---
title: "The Cifti Data Structure in R"
format: 
  html:
    theme: 
      light: sandstone
      dark: darkly
    toc: true
    toc-depth: 4
---

## Introduction

The [CIFTI](https://www.humanconnectome.org/software/workbench-command/-cifti-help) format is a neuroimaging data format designed by researchers involved with the Human Connectome Project to make working with disjoint data (typically cortical and subcortical) at the same time easier. CIFTI (and GIFTI) are standard outputs from the [HCP Preprocessing Pipeline](https://uab-cinl.github.io/analysis/hcp_pipelines/) and can be generated using [fmriprep](https://uab-cinl.github.io/analysis/fmriprep/) or [ciftify](https://github.com/edickie/ciftify) as well, but very little information exists on how to use these formats during data analysis within different platforms. This guide will cover how to import and use these data structures in R.

All data used in this tutorial comes from the [HCP Young Adult Dataset](https://www.humanconnectome.org/study/hcp-young-adult). These data are freely available for research or learning purposes from their [online repository](db.humanconnectome.org). The exact subject numbers won't be shared here, but all participants in that study who had at least one MRI session will have the same data files. If you would like to practice on these data, you can download the Preprocessed data for some participants, but be aware a full preprocessed dataset can be upwards of 60 GB per person. Here, we will only look at structural preprocessed data (derived from T1w and T2w) and a single preprocessed resting state scan.

:::{.callout-note}
Packages specific to gifti and cifti structures will be introduced below, but we will also be using the [tidyverse](https://www.tidyverse.org/) suite of packages for data wrangling as well.
:::

```{r load tidyverse}
#| echo: false
#| message: false

library(tidyverse)
```


## GIFTI

We will start with gifti because it is an easier format to understand and will help organize cifti data later on. All gifti data can be loaded using the [gifti](https://cran.r-project.org/web/packages/gifti/index.html) library which can be downloaded from CRAN.

```{r load gifti library}
#| message: false

library(gifti)
```

All gifti data will be loaded using the `read_gifti` command. `readgii` and `readGIFTI` are both aliases for `read_gifti` and so can be used the same way as well if you prefer typing one of those. The output of these commands will be a named list.

### Surfaces

All gifti files describe some form of information about a single cortical hemisphere, no subcortical information is included. All generated gifti files from a standard preprocessing pipeline will include which hemisphere the gifti describes in the name (a practice everyone should use). The most common giftis will be the structural surfaces themselves that other data are shown on. These files always end with the `surf.gii` extension.

![](images/pial_surface.png){fig-align="center"}

As said above, these surfaces can be imported using one of gifti's `read` functions.

```{r read pial surfaces}
lhpial <- read_gifti('data/102109/fsaverage_LR32k/102109.L.pial.32k_fs_LR.surf.gii')
rhpial <- read_gifti('data/102109/fsaverage_LR32k/102109.R.pial.32k_fs_LR.surf.gii')
```

Lists from gifti files are going to have 8 top-level fields with the following names:

```{r list lhpial fields}
names(lhpial)
```


Most of the interesting information is in the `data` field of the output list.

```{r show lhpial struct}
glimpse(lhpial$data)
```

You can see that for the lh pial surface, `data` has two subfields: `pointset` and `triangle`. `pointset` gives the spatial coordinates for each vertex on the surface which will change between pial, inflated, very inflated, etc. surfaces, and `triangle` gives a list of vertices that make up each face which does not change between surfaces. The actual data in the `pointset` and `triangle` fields won't be useful that often, the important part is the total number of vertices which you can get from the number of rows in `pointset`. You can see this surface has `r nrow(lhpial$data$pointset)` vertices, and the right hemisphere surfaces also have `r nrow(rhpial$data$pointset)` vertices. The `fsaverage_LR32k` surfaces are in a template space, and each surface should have the same number of vertices across participants. The same goes for the 164k surfaces, but the number of vertices is larger. If you're working with the native space surfaces, the number of vertices will be dependent on subject and hemisphere.

#### Metadata

Other data of interest in the surface files can be found in the `data_meta` field such as the primary and secondary structure the surface describes in case this information was left out of the file name. 

### Metric and Label Data

All other gifti files should have extensions such as `func.gii`, `shape.gii`, or `label.gii`. These contain data that describe some property of vertices on the surface such as thickness, curvature, or timeseries data. Again, these can also be loaded using one of the `read` commands above.

#### Metric

Metric data contain continuous values and are stored in `func.gii` or `shape.gii` files depending on whether the data describe functional or structural information. For example, we can load the thickness surfaces. The surface overlays can be seen below.

![](images/pial_thickness.png){fig-align="center"}

```{r load thickness}
lhthick <- read_gifti('data/102109/fsaverage_LR32k/102109.L.thickness.32k_fs_LR.shape.gii')
rhthick <- read_gifti('data/102109/fsaverage_LR32k/102109.R.thickness.32k_fs_LR.shape.gii')
```

These surfaces will have the same fields as the surface files.

```{r list lhthick fields}
names(lhthick)
```

Similar to last time, the `data` field is the one of main interest and will contain at least one subfield, `normal` in this case.

```{r glimpse lh thickness data}
glimpse(lhthick$data)
```

For all metric giftis, the number of values equals the number of vertices on the surface. This is the case even if some vertices would not have a reasonable value. For example, vertices making up the medial wall do not have a calculated thickness and are uncolored in the above image. The thickness gifti assigns a numeric value to them anyway since those vertices need to be accounted for and will assign a value of 0 in this case. This is not the case for cifti data which will be seen later. There are `r sum(lhthick$data$normal != 0)` vertices on the left hemisphere and `r sum(rhthick$data$normal != 0)` on the right that have a measurable thickness.

:::{.callout-important}
## Base-0 and Base-1 Indexing

Be aware that R uses base-1 indexing, but the vertex numbering system is base-0. This means that vertex 0 on the surface has the thickness value assigned at index 1 in R. For example, we can get the thickness of vertex 1978 for a participant in wb_view, seen below.

![](images/vertex_thickness.png){fig-align='center'}

But index 1978 has thickness value `r round(lhthick$data$normal[1978],5)`. To get the correct thickness value for this vertex, you would get the thickness from index 1979 of `r round(lhthick$data$normal[1979],5)`.
:::

While thickness data are stored in an array because each vertex only has a single thickness value, functional timeseries data are stored as a matrix. Functional data can be loaded and interacted with the same way though.

```{r load functional data}
#| cache: true

lhrest_native <- read_gifti('data/102109/Results/rfMRI_REST1_LR/rfMRI_REST1_LR.L.native.func.gii')
```

:::{.callout-note}
Here, we are loading the native space version of the resting state scan because the preprocessed data did not have gifti versions of the functional scans in fs_LR_32k space. The number of vertices will differ, but the idea is exactly the same.
:::

```{r}
glimpse(lhrest_native$data[1:5])

length(lhrest_native$data)
```

Now, the `data` field has more than one subfield, it now has `r length(lhrest_native$data)` subfields. This represents the `r length(lhrest_native$data)` timepoints in the scan. Each one of the subfields has `r length(lhrest_native$data[[1]])` values in it representing the scan value at each vertex in that hemisphere for a given timepoint (on the native space surface). Each timepoint is stored as an individual list of functional values within the `data` field.

Storing timepoints as a series of lists can make the data difficult to work with. We can instead extract the data and store it in a simplified 2D matrix. Columns will represent timepoints which rows represent vertices, the standard representation for CIFTI data.

```{r gifti func to matrix}
#| cache: true

lhrest_native_data <- do.call(cbind,lhrest_native$data)
nrow(lhrest_native_data)
ncol(lhrest_native_data)
```

`lhrest_native_data` has been created as a matrix with `r nrow(lhrest_native_data)` rows each corresponding to a vertex and `r ncol(lhrest_native_data)` columns each corresponding to a timepoint. 

An important note is that this matrix takes up a large amount of memory because there are `r length(lhrest_native_data)` elements in the matrix for one hemisphere of one person. When using this sort of data across a large number of participants, you will need a large amount of memory or do some form of summarization as data is being imported using a custom function. This may be the case even for fs_LR_32k space data even though the number of vertices per hemisphere is much smaller than the native space scan used here.


#### Label

Label data are made up of integer values that each map to different names, typically for regions of interest or parcellation areas. Here, we will load the aparc label files that are automatically generated and transferred from FreeSurfer.

```{r load labels}
lhlabel <- read_gifti('data/102109/fsaverage_LR32k/102109.L.aparc.32k_fs_LR.label.gii')
rhlabel <- read_gifti('data/102109/fsaverage_LR32k/102109.R.aparc.32k_fs_LR.label.gii')
```

These label files have the same structure as the metric files above where the `data` field gives the integer assignment for each vertex, but the `label` field is also used to give a list of names assigned to the integers as well as their RGB value for plotting on a surface.

```{r get label names}
lhlabel$label
```

You can see there's an integer value 0 in the table that vertices with an unknown assignment might be given instead. Vertices with no label assignment at all will have a value of -1. It will be meaningful to filter out vertices that have values of either 0 or -1 when performing analyses.

## CIFTI

CIFTI files are a file type that can combine data from both hemispheres as well as subcortical regions. All cifti files can be imported using the [cifti](https://cran.r-project.org/web/packages/cifti/cifti.pdf) package which can be installed from CRAN. The cifti package also installs `gifti` as a dependency.

```{r load cifti library}
library(cifti)
```

As opposed to gifti, cifti files can contain information about both hemispheres as well as subcortical regions in the same file. The basic import function is `read_cifti` (`readcii` and `readCIFTI` are also aliases). For example, we can go ahead and read in the subject's thickness cifti file.

```{r read thickness}
#| cache: true
thick_cii <- read_cifti('data/102109/fsaverage_LR32k/102109.thickness.32k_fs_LR.dscalar.nii')
```

The cifti list structure in R is slightly different from the gifti structure. 

```{r thick variables}
names(thick_cii)
```

Here, we will have a few fields of interest:

1. `NamedMap`: contains a list of map names if multiple maps are stored in the same file. For instance, curvature, thickness, and Myelin values could all be stored in the same CIFTI file.
2. `BrainModel`: List of brainordinates which have data. Brainordinates from different areas will be stored in different lists within `BrainModel`. Sometimes, the names of the areas are not given in the structure but can be read directly from the cifti file. See below.
3. `data`: field containing the data of interest. Data are stored in a 1D array or 2D matrix where rows refer to the brainordinates concatenated from different areas. For 2D data, columns are typically timepoints.

As opposed to gifti data from above, only brainordinates that have data assigned to them are given in the `data` field. In order to accurately assign data to the correct brainordinate and area, you need to use the values from the `BrainModel` field. For example, let's look at the thickness cifti file we loaded earlier.

```{r thick BrainModel}
glimpse(thick_cii$BrainModel)
```

We can see there are `r length(thick_cii$BrainModel[[1]])` thickness values assigned to the left cortex and `r length(thick_cii$BrainModel[[2]])` assigned to the right cortex and the data are the vertex numbers which have thickness data. The `data` field is concatenated in order of subfields in `BrainModel`. In other words, the first `r length(thick_cii$BrainModel[[1]])` rows are left hemisphere data and the last `r length(thick_cii$BrainModel[[2]])` rows are right hemisphere data if there is only cortical data. For ciftis with both cortical and subcortical areas, subcortical data will be concatenated following the right hemisphere.

### Subcortical Area Names

While the cortical hemispheres are named in the cifti's R structure, the subcortical areas are not. For example, we can import a cifti with resting state data for both cortex and subcortical areas and look at the attributes for the first 4 areas.

```{r load rest cifti}
#| cache: true
rest_cii <- read_cifti('data/102109/Results/rfMRI_REST1_LR/rfMRI_REST1_LR_Atlas.dtseries.nii')
glimpse(rest_cii$BrainModel[1:4])
```

The first two areas are both left and right cortex and have an attribute saying their name, but the following subcortical areas are unnamed in this structure. This makes it impossible to tell explicitly which area each subcortical list belongs to just from this data structure.

To get around this, we can take advantage of the fact the cifti format is essentially a fancy XML file and just read the text information directly using `cifti_xml_txt`.

```{r read XML text}
txt <- cifti_xml_txt('data/102109/Results/rfMRI_REST1_LR/rfMRI_REST1_LR_Atlas.dtseries.nii')
```

This gives us a single string with all of the text information from the cifti file in it. Looking at the cifti file in a text editor, we can see that each area name begins with the string "CIFTI_STRUCTURE_". So to get all of the area names, we can extract strings that begin with "CIFTI_STRUCTURE_" using a regex.

```{r areas}
areas <- str_extract_all(txt,'CIFTI_STRUCTURE_[A-Z_]+')[[1]]
areas
```

The `r length(areas)` area names matches the `r length(rest_cii$BrainModel)` list entries. If you are only looking for data from a subset of the areas listed here, you can grab those lists via indexing (i.e. data from the left and right hippocampus would be in `rest_cii$BrainModel[14]` and `rest_cii$BrainModel[15]`, respectively).

:::{.callout-note}
It's important to note that the area names may not always begin with "CIFTI_STRUCTURE_" depending on who or what made them. You can easily open the cifti file in a text editor such as Notepad++ and search for the "BrainStructure" tags to see if there is a pattern to the area names.
:::

### Converting to Data Frame

If you are using other packages such as the `tidyverse` for analyzing cifti data, it would make sense to convert the cifti list structure to a data frame (or tibble) first for data wrangling. I recommend keeping cortical data separate from subcortical data because they do not share a common ID format. In other words, cortical cifti data are identified via single vertex numbers while subcortical cifti data are identified using 3 coordinate locations. Keeping cortical and subcortical data in the same data frame would have 4 ID columns that are not shared among all of the data. If you do not need any form of brainordinate identifier beyond the area name, then keeping cortical and subcortical data together is fine

Extracting cortical data from ciftis where the data is an array (such as thickness) is simple and straightforward.

```{r cortical thickness}
lhvert <- length(thick_cii$BrainModel[[1]]) # number of left hemisphere vertices
rhvert <- length(thick_cii$BrainModel[[2]]) # number of right hemisphere vertices

cortical_thick <- tibble(hemi = rep(c('LH','RH'),times = c(lhvert,rhvert)),
                         vertex = c(thick_cii$BrainModel[[1]],
                                    thick_cii$BrainModel[[2]]), # concatenate the vertex numbers
                         thickness = thick_cii$data[1:(lhvert + rhvert)]) # get data for all vertices

head(glimpse(cortical_thick))
```

For this, we do need the hemisphere designation because vertex numbers are not unique across hemispheres. Because the array of thickness data can easily be converted to a column in a data frame, there's very little other data wrangling to perform. This isn't the case for 2D cifti data such as timeseries where there are a couple of extra steps needed to convert the timeseries matrix to a data frame itself.

```{r cortical rest}
#| cache: true
lhvert <- length(rest_cii$BrainModel[[1]]) # number of left hemisphere vertices
rhvert <- length(rest_cii$BrainModel[[2]]) # number of right hemisphere vertices

# get the cortical data from the dataframe, name columns by their TR number, then convert to a tibble
cort_ts <- rest_cii$data[1:(lhvert+rhvert),] 
colnames(cort_ts) <- sprintf('TR_%s',seq(1,ncol(rest_cii$data)))
cort_ts <- as_tibble(cort_ts)

# add vertex and hemisphere designation to time series
cortical_rest <- tibble(hemi = rep(areas[1:2],times = c(lhvert,rhvert)),
                        vertex = c(rest_cii$BrainModel[[1]],
                                   rest_cii$BrainModel[[2]]),
                        cort_ts)

cortical_rest
```

For subcortical areas, there is a bit more wrangling to do since these brainordinates use i, j, and k positional values as opposed to single numbers, and there are `r length(rest_cii$BrainModel) - 2` subcortical areas that will need to be replicated as opposed to just the two hemispheres.

```{r subcortical rest}
#| cache: true

# calculate total number of cortical vertices to know how many rows to skip in the data field
cort_vert <- length(rest_cii$BrainModel[[1]]) + length(rest_cii$BrainModel[[2]])

# get ordinate counts of all subcortical areas
subcortical_ordinate_count <- sapply(rest_cii$BrainModel,nrow,simplify = TRUE)

# set up coordinates information with proper column names
coords <- do.call(rbind,rest_cii$BrainModel[-(1:2)])
colnames(coords) <- c('i','j','k')
coords <- as_tibble(coords)

# get the subcortical data from the dataframe, name columns by their TR number, then convert to a tibble
subcort_ts <- rest_cii$data[-(1:cort_vert),] # -(1:(lhvert+rhvert)) removes rows from index 1 to cort_vert
colnames(subcort_ts) <- sprintf('TR_%s',seq(1,ncol(rest_cii$data)))
subcort_ts <- as_tibble(subcort_ts)

subcortical_rest <- tibble(area = rep(areas[-(1:2)], times = subcortical_ordinate_count[-(1:2)]),
                           coords,
                           subcort_ts)

subcortical_rest
```

We pretty much set up each individual component of the subcortical data frame outside of the `tibble` command because of the wrangling, so if you need to conserve memory be sure to delete the intermediate variables with `rm`.

Remember, these steps are only creating a dataframe for a single person, but the size of the cortical and subcortical resting state data frames are `r prod(dim(subcortical_rest)) + prod(dim(cortical_rest))` and this is not including other demographic variables such as participant ID and group. As opposed to creating full data frames for all your participants and then filtering afterwards, it will be useful to filter and curate data for each participant as they are being imported using a function.
