{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"UAB CINL Documentation \u00b6 About \u00b6 The Civitan International Neuroimaging Laboratory provides a core resource at UAB for state-of-the-art MRI neuroimaging experiments and analyses for examining brain and body anatomy and function both in health and disease. This houses technical information for CINL pertaining to both scanner procedures as well as data storage, organization, pre-processing, and processing on UAB's computing cluster Cheaha. Cheaha provides researchers with both data storage space as well as a large amount of computational power necessary for high-throughput neuroimaging analysis. Access to the Cheaha cluster is free for UAB researchers. Request an account using the following instructions Websites \u00b6 For more information about MRI cores at UAB, please visit the following pages: UAB CINL: https://www.uab.edu/medicine/cinl Research MRI Core: https://www.uab.edu/cores/ircp/rmric Note This project is under active development. To request changes or additions to the documentation, please submit an issue to the main Github Repository","title":"Home"},{"location":"#uab-cinl-documentation","text":"","title":"UAB CINL Documentation"},{"location":"#about","text":"The Civitan International Neuroimaging Laboratory provides a core resource at UAB for state-of-the-art MRI neuroimaging experiments and analyses for examining brain and body anatomy and function both in health and disease. This houses technical information for CINL pertaining to both scanner procedures as well as data storage, organization, pre-processing, and processing on UAB's computing cluster Cheaha. Cheaha provides researchers with both data storage space as well as a large amount of computational power necessary for high-throughput neuroimaging analysis. Access to the Cheaha cluster is free for UAB researchers. Request an account using the following instructions","title":"About"},{"location":"#websites","text":"For more information about MRI cores at UAB, please visit the following pages: UAB CINL: https://www.uab.edu/medicine/cinl Research MRI Core: https://www.uab.edu/cores/ircp/rmric Note This project is under active development. To request changes or additions to the documentation, please submit an issue to the main Github Repository","title":"Websites"},{"location":"analysis/mriqc/","text":"MRIQC \u00b6 MRIQC is a software suite that extracts image quality metrics from unprocessed T1w, T2w, and functional data for visual inspection and overall quality control. MRIQC is a BIDS app so data will need to be converted to BIDS format before MRIQC is run. More information about MRIQC as well as the information needed to cite the software can be found in theie documentation . Installation \u00b6 MRIQC is designed to be easily used as a Docker/Singularity container. There is a bare-metal Python3 installation available, however it requires other dependencies (some versions of which may not be released at the time) and is not recommended. In order to download the MRIQC Singularity container, start an HPC Desktop session at https://rc.uab.edu , then open a terminal and navigate to the location you would like to store the container file. Then run the following commands: module load Singularity singularity pull mriqc-0.16.1.sif docker://poldracklab/mriqc:0.16.1 The container creation process will take a while to run, but once downloaded, this container will not need to be downloaded again unless a new version comes out that you would like to use instead. Usage \u00b6 The basic command for running MRIQC will look like the following: singularity run mriqc-0.16.1.sif \\ [ optional inputs ] \\ <bids_dir> \\ <output_dir> \\ <analysis level> All available options for use with the mriqc can be seen using singularity run mriqc-0.16.1.sif --help . Below are a list of selected options. The positional arguments are the only ones required to used. Positional Arguments \u00b6 bids_dir : the path to the directory with BIDS formatted data output_dir : the path to the output directory. If you are running group level analysis this folder should be prepopulated with the results of the participant level analysis. analysis_level : either set to participant or group. Filtering Data \u00b6 --participant-label : one or more participant identifiers without the sub- prefix. Separate multiple labels with spaces --session-id : the session ID to perform on, if one exists. Instrumental Options \u00b6 --work-dir : change the working directory that stores intermediate results --no-sub : turn off submission of anonymized quality metrics to MRIQC's metrics repo Performance Options \u00b6 --nprocs : number of compute threads --mem_gb : amount of total memory available in GB Outputs \u00b6 Participant Level \u00b6 All relevant outputs of mriqc are in html files and can be opened in your native web browser. On Cheaha, Firefox is installed and available by default for all users. When running on a single participant level, one html file is output for each structural or functional scan. Each output will show a set of slices for the scan in the horizontal and sagittal planes for visual inspection. The average BOLD signal is presented for 4D images. These images can be used to identify various artifacts such as ghosting, motion-induced ringing, coil failures, and others that may have been missed during the scan session. These artifacts are able to be marked on the html output and a rating given to the scan. In addition, for 4D images, motion metrics are given as well. DVARS and framewise displacement are both given as measures of head motion over time. Both are presented in absolute units and framewise displacement is given a cutoff line of 0.2 mm total on the graph so you can estimate how many frames went above that specific threshold. For all scans, numerous single-value image quality metrics (IQMs) are provided for interpretation after the visual reports section. For information on these IQMs, please visit MRIQC's documentation . It's important to note that no alterations are made to the raw data during MRIQC. Volumes with extreme motion are still there afterwards, and it is up to the investigator to decide how to deal with them. This tool just provides you general information on overall scan quality to determine whether to remove it from the study or not. Group Level \u00b6 Group level outputs read from the participant level html files and aggregate data into single files for each scan. Interactive graphs are made with distributions of each IQM, and each data point links to the report it came from. This means you can inspect the group level and then immediately navigate to scans with outlier IQM values for a closer inspection. Additonally, you can click the names of the IQMs to be taken to the docs for an explanation of what the measure is. Example Scripts \u00b6 Single Subject \u00b6 #!/bin/bash # #SBATCH --job-name=mriqc #SBATCH --output=mriqc_out.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=amd-hdr100 #SBATCH --time=6:00:00 #SBATCH --mem-per-cpu=40G module load Singularity/3.5.2-GCC-5.4.0-2.26 # set the BIDS directory export bidsdir = $USER_DATA /D01/nifti/ singularity run ~/Scripts/mriqc/mriqc-0.16.1.sif \\ --participant-label S01 S02 \\ --n_procs 1 \\ --mem_gb 40 \\ --no-sub \\ ${ bidsdir } \\ ${ bidsdir } /derivatives/mriqc \\ participant Group Stats \u00b6 #!/bin/bash # #SBATCH --job-name=mriqc_group #SBATCH --output=mriqc_group.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=amd-hdr100 #SBATCH --time=2:00:00 #SBATCH --mem-per-cpu=8G module load Singularity/3.5.2-GCC-5.4.0-2.26 # set the BIDS directory export bidsdir = $USER_DATA /D01/nifti/ singularity run ~/Scripts/mriqc/mriqc-0.16.1.sif \\ --no-sub \\ ${ bidsdir } \\ ${ bidsdir } /derivatives/mriqc \\ group","title":"MRIQC"},{"location":"analysis/mriqc/#mriqc","text":"MRIQC is a software suite that extracts image quality metrics from unprocessed T1w, T2w, and functional data for visual inspection and overall quality control. MRIQC is a BIDS app so data will need to be converted to BIDS format before MRIQC is run. More information about MRIQC as well as the information needed to cite the software can be found in theie documentation .","title":"MRIQC"},{"location":"analysis/mriqc/#installation","text":"MRIQC is designed to be easily used as a Docker/Singularity container. There is a bare-metal Python3 installation available, however it requires other dependencies (some versions of which may not be released at the time) and is not recommended. In order to download the MRIQC Singularity container, start an HPC Desktop session at https://rc.uab.edu , then open a terminal and navigate to the location you would like to store the container file. Then run the following commands: module load Singularity singularity pull mriqc-0.16.1.sif docker://poldracklab/mriqc:0.16.1 The container creation process will take a while to run, but once downloaded, this container will not need to be downloaded again unless a new version comes out that you would like to use instead.","title":"Installation"},{"location":"analysis/mriqc/#usage","text":"The basic command for running MRIQC will look like the following: singularity run mriqc-0.16.1.sif \\ [ optional inputs ] \\ <bids_dir> \\ <output_dir> \\ <analysis level> All available options for use with the mriqc can be seen using singularity run mriqc-0.16.1.sif --help . Below are a list of selected options. The positional arguments are the only ones required to used.","title":"Usage"},{"location":"analysis/mriqc/#positional-arguments","text":"bids_dir : the path to the directory with BIDS formatted data output_dir : the path to the output directory. If you are running group level analysis this folder should be prepopulated with the results of the participant level analysis. analysis_level : either set to participant or group.","title":"Positional Arguments"},{"location":"analysis/mriqc/#filtering-data","text":"--participant-label : one or more participant identifiers without the sub- prefix. Separate multiple labels with spaces --session-id : the session ID to perform on, if one exists.","title":"Filtering Data"},{"location":"analysis/mriqc/#instrumental-options","text":"--work-dir : change the working directory that stores intermediate results --no-sub : turn off submission of anonymized quality metrics to MRIQC's metrics repo","title":"Instrumental Options"},{"location":"analysis/mriqc/#performance-options","text":"--nprocs : number of compute threads --mem_gb : amount of total memory available in GB","title":"Performance Options"},{"location":"analysis/mriqc/#outputs","text":"","title":"Outputs"},{"location":"analysis/mriqc/#participant-level","text":"All relevant outputs of mriqc are in html files and can be opened in your native web browser. On Cheaha, Firefox is installed and available by default for all users. When running on a single participant level, one html file is output for each structural or functional scan. Each output will show a set of slices for the scan in the horizontal and sagittal planes for visual inspection. The average BOLD signal is presented for 4D images. These images can be used to identify various artifacts such as ghosting, motion-induced ringing, coil failures, and others that may have been missed during the scan session. These artifacts are able to be marked on the html output and a rating given to the scan. In addition, for 4D images, motion metrics are given as well. DVARS and framewise displacement are both given as measures of head motion over time. Both are presented in absolute units and framewise displacement is given a cutoff line of 0.2 mm total on the graph so you can estimate how many frames went above that specific threshold. For all scans, numerous single-value image quality metrics (IQMs) are provided for interpretation after the visual reports section. For information on these IQMs, please visit MRIQC's documentation . It's important to note that no alterations are made to the raw data during MRIQC. Volumes with extreme motion are still there afterwards, and it is up to the investigator to decide how to deal with them. This tool just provides you general information on overall scan quality to determine whether to remove it from the study or not.","title":"Participant Level"},{"location":"analysis/mriqc/#group-level","text":"Group level outputs read from the participant level html files and aggregate data into single files for each scan. Interactive graphs are made with distributions of each IQM, and each data point links to the report it came from. This means you can inspect the group level and then immediately navigate to scans with outlier IQM values for a closer inspection. Additonally, you can click the names of the IQMs to be taken to the docs for an explanation of what the measure is.","title":"Group Level"},{"location":"analysis/mriqc/#example-scripts","text":"","title":"Example Scripts"},{"location":"analysis/mriqc/#single-subject","text":"#!/bin/bash # #SBATCH --job-name=mriqc #SBATCH --output=mriqc_out.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=amd-hdr100 #SBATCH --time=6:00:00 #SBATCH --mem-per-cpu=40G module load Singularity/3.5.2-GCC-5.4.0-2.26 # set the BIDS directory export bidsdir = $USER_DATA /D01/nifti/ singularity run ~/Scripts/mriqc/mriqc-0.16.1.sif \\ --participant-label S01 S02 \\ --n_procs 1 \\ --mem_gb 40 \\ --no-sub \\ ${ bidsdir } \\ ${ bidsdir } /derivatives/mriqc \\ participant","title":"Single Subject"},{"location":"analysis/mriqc/#group-stats","text":"#!/bin/bash # #SBATCH --job-name=mriqc_group #SBATCH --output=mriqc_group.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=amd-hdr100 #SBATCH --time=2:00:00 #SBATCH --mem-per-cpu=8G module load Singularity/3.5.2-GCC-5.4.0-2.26 # set the BIDS directory export bidsdir = $USER_DATA /D01/nifti/ singularity run ~/Scripts/mriqc/mriqc-0.16.1.sif \\ --no-sub \\ ${ bidsdir } \\ ${ bidsdir } /derivatives/mriqc \\ group","title":"Group Stats"},{"location":"analysis/resources/","text":"Resources \u00b6 This page provides links to written documentation, tutorials, and videos for relevent software in neuroimaging analysis. Most video links on the page will go to the MRI analysis playlist on UAB Research Computing's Youtube channel. BIDS \u00b6 BIDS Specification Documentation BIDS Apps BIDS Workshop (UAB Feb 2022) Github Repo Presentation Recording fmriprep \u00b6 Main fmriprep docs fmriprep Cheaha Video Tutorial MRIQC \u00b6 Main MRIQC Docs MRIQC Cheaha Video Tutorial QSIprep \u00b6 Main QSIprep Docs QSIprep Cheaha Video Tutorial","title":"Resources"},{"location":"analysis/resources/#resources","text":"This page provides links to written documentation, tutorials, and videos for relevent software in neuroimaging analysis. Most video links on the page will go to the MRI analysis playlist on UAB Research Computing's Youtube channel.","title":"Resources"},{"location":"analysis/resources/#bids","text":"BIDS Specification Documentation BIDS Apps BIDS Workshop (UAB Feb 2022) Github Repo Presentation Recording","title":"BIDS"},{"location":"analysis/resources/#fmriprep","text":"Main fmriprep docs fmriprep Cheaha Video Tutorial","title":"fmriprep"},{"location":"analysis/resources/#mriqc","text":"Main MRIQC Docs MRIQC Cheaha Video Tutorial","title":"MRIQC"},{"location":"analysis/resources/#qsiprep","text":"Main QSIprep Docs QSIprep Cheaha Video Tutorial","title":"QSIprep"},{"location":"analysis/bids/","text":"BIDS \u00b6 The BIDS data structure refers to a method of organizing and naming nifti and associated JSON files for each MRI scan. Organizing data according to the BIDS framework opens up access to various software applications that only act on BIDS compliant datasets, such as fmriprep, mriqc, and qsiprep. Additionally, matching structures across datasets makes navigation, exploration, and sharing of datasets much easier. A short introduction to BIDS along with examples of BIDS compliant file structures can be found in these docs. Read more about the BIDS framework at https://bids-specification.readthedocs.io/ . Conversion from DICOM to BIDS \u00b6 While writing custom code to convert from DICOM files to the BIDS framework is possible, tools have been to make this more automatic and reproducible across datasets. This documentation provides information and examples on one of those resources, HeuDiConv .","title":"Introduction"},{"location":"analysis/bids/#bids","text":"The BIDS data structure refers to a method of organizing and naming nifti and associated JSON files for each MRI scan. Organizing data according to the BIDS framework opens up access to various software applications that only act on BIDS compliant datasets, such as fmriprep, mriqc, and qsiprep. Additionally, matching structures across datasets makes navigation, exploration, and sharing of datasets much easier. A short introduction to BIDS along with examples of BIDS compliant file structures can be found in these docs. Read more about the BIDS framework at https://bids-specification.readthedocs.io/ .","title":"BIDS"},{"location":"analysis/bids/#conversion-from-dicom-to-bids","text":"While writing custom code to convert from DICOM files to the BIDS framework is possible, tools have been to make this more automatic and reproducible across datasets. This documentation provides information and examples on one of those resources, HeuDiConv .","title":"Conversion from DICOM to BIDS"},{"location":"analysis/bids/heudiconv_scripts/","text":"Example Scripts \u00b6 This page list a couple of example jobs to submit to SLURM for running Step 3 of HeuDiConv where actual BIDS sorting occurs. In general, the time, partition, number of cores, and memory should be sufficient for converting any dataset. Paths inside the script should be changed to fit the user's dataset and file structure. Note Replace anything inside <> (including those symbols) with the relevant information, whether it is a path, or something else. If they are left in, the scripts will not run. Create Conda Environment \u00b6 #!/bin/bash # #SBATCH --job-name=create-bids-env #SBATCH --output=bids-env.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=express #SBATCH --time=20:00 #SBATCH --mem-per-cpu=8G #SBATCH --mail-type=FAIL module load Anaconda3/2020.11 conda create -n bids conda activate bids pip install heudiconv == 0 .9.0 conda install -c conda-forge dcm2niix Single Subject Job \u00b6 This job assumes each subject only has a single session of data to convert and does not use the session variable. Note The conversion scripts assume dicoms are stored in the same folder structure as in the practical HeuDiConv example . If your directory structure differs, or there are multiple sessions, you will need to alter the path for the -d input to account for these differences #!/bin/bash # #SBATCH --job-name=bids #SBATCH --output=array-out/bids.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=express #SBATCH --time=30:00 #SBATCH --mem-per-cpu=8G #SBATCH --mail-type=FAIL # set necessary variables base_dir = <path/to/dataset> subject = <base subject name> # load the necessary Anaconda module and activate the virtual environment. The heudiconv executable is in ~/.local/bin, so add that to the PATH module load Anaconda3/2020.11 conda activate bids PATH = $PATH :~/.local/bin # Run heudiconv heudiconv -s $subject -d <path/to/find/all/subject/dicom/files> -o $base_dir /nifti -f <path/to/heuristic> -c dcm2niix -b --overwrite # change the permissions of all of the files in the BIDS directory to have user and group write permissions find $base_dir /nifti/<BIDS subject name> -exec chmod ug+w {} \\; find $base_dir /nifti/.heudiconv/<BIDS subject name> -exec chmod ug+w {} \\; Array Job \u00b6 The array job will replicate the job across multiple subjects' data without having to create individual job scripts to submit. For more information about array jobs and how to submit them, read the UAB Research Computing documentation. base_dir should be changed to the path to the dataset folder, the directory that contains the dicom folder and the newly created nifti folder. This job assumes each subject only has a single session of data to convert and does not use the session variable. Note The conversion scripts assume dicoms are stored in the same folder structure as in the practical HeuDiConv example . If your directory structure differs, or there are multiple sessions, you will need to alter the path for the -d input to account for these differences #!/bin/bash # #SBATCH --job-name=bids #SBATCH --output=array-out/bids-%A-%a.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=express #SBATCH --time=30:00 #SBATCH --mem-per-cpu=8G #SBATCH --mail-type=FAIL # set the path to the base directory and change directory to the dicom # directory inside it. base_dir = <path/to/dataset> cd $base_dir /dicom # load the necessary Anaconda module and activate the virtual environment. The heudiconv executable is in ~/.local/bin, so add that to the PATH module load Anaconda3/2020.11 conda activate bids PATH = $PATH :~/.local/bin # Get the subject name based on the array index # For example, if I wanted to get all the folders the began with UAB, it would be subs=(UAB*) # These subjects should be in $base_dir, so plan accordingly. subs =( <glob to get the names of all the subjects> ) pid = \" ${ subs [ $SLURM_ARRAY_TASK_ID ] } \" # Run heudiconv heudiconv -s $pid -d <path/to/find/all/subject/dicom/files> -o $base_dir /nifti -f <path/to/heuristic> -c dcm2niix -b --overwrite # change the permissions of all of the files in the BIDS directory to have user and group write permissions find $base_dir /nifti/sub- ${ pid //_ } -exec chmod ug+w {} \\; find $base_dir /nifti/.heudiconv/ ${ pid //_ } -exec chmod ug+w {} \\;","title":"Example Scripts"},{"location":"analysis/bids/heudiconv_scripts/#example-scripts","text":"This page list a couple of example jobs to submit to SLURM for running Step 3 of HeuDiConv where actual BIDS sorting occurs. In general, the time, partition, number of cores, and memory should be sufficient for converting any dataset. Paths inside the script should be changed to fit the user's dataset and file structure. Note Replace anything inside <> (including those symbols) with the relevant information, whether it is a path, or something else. If they are left in, the scripts will not run.","title":"Example Scripts"},{"location":"analysis/bids/heudiconv_scripts/#create-conda-environment","text":"#!/bin/bash # #SBATCH --job-name=create-bids-env #SBATCH --output=bids-env.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=express #SBATCH --time=20:00 #SBATCH --mem-per-cpu=8G #SBATCH --mail-type=FAIL module load Anaconda3/2020.11 conda create -n bids conda activate bids pip install heudiconv == 0 .9.0 conda install -c conda-forge dcm2niix","title":"Create Conda Environment"},{"location":"analysis/bids/heudiconv_scripts/#single-subject-job","text":"This job assumes each subject only has a single session of data to convert and does not use the session variable. Note The conversion scripts assume dicoms are stored in the same folder structure as in the practical HeuDiConv example . If your directory structure differs, or there are multiple sessions, you will need to alter the path for the -d input to account for these differences #!/bin/bash # #SBATCH --job-name=bids #SBATCH --output=array-out/bids.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=express #SBATCH --time=30:00 #SBATCH --mem-per-cpu=8G #SBATCH --mail-type=FAIL # set necessary variables base_dir = <path/to/dataset> subject = <base subject name> # load the necessary Anaconda module and activate the virtual environment. The heudiconv executable is in ~/.local/bin, so add that to the PATH module load Anaconda3/2020.11 conda activate bids PATH = $PATH :~/.local/bin # Run heudiconv heudiconv -s $subject -d <path/to/find/all/subject/dicom/files> -o $base_dir /nifti -f <path/to/heuristic> -c dcm2niix -b --overwrite # change the permissions of all of the files in the BIDS directory to have user and group write permissions find $base_dir /nifti/<BIDS subject name> -exec chmod ug+w {} \\; find $base_dir /nifti/.heudiconv/<BIDS subject name> -exec chmod ug+w {} \\;","title":"Single Subject Job"},{"location":"analysis/bids/heudiconv_scripts/#array-job","text":"The array job will replicate the job across multiple subjects' data without having to create individual job scripts to submit. For more information about array jobs and how to submit them, read the UAB Research Computing documentation. base_dir should be changed to the path to the dataset folder, the directory that contains the dicom folder and the newly created nifti folder. This job assumes each subject only has a single session of data to convert and does not use the session variable. Note The conversion scripts assume dicoms are stored in the same folder structure as in the practical HeuDiConv example . If your directory structure differs, or there are multiple sessions, you will need to alter the path for the -d input to account for these differences #!/bin/bash # #SBATCH --job-name=bids #SBATCH --output=array-out/bids-%A-%a.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --partition=express #SBATCH --time=30:00 #SBATCH --mem-per-cpu=8G #SBATCH --mail-type=FAIL # set the path to the base directory and change directory to the dicom # directory inside it. base_dir = <path/to/dataset> cd $base_dir /dicom # load the necessary Anaconda module and activate the virtual environment. The heudiconv executable is in ~/.local/bin, so add that to the PATH module load Anaconda3/2020.11 conda activate bids PATH = $PATH :~/.local/bin # Get the subject name based on the array index # For example, if I wanted to get all the folders the began with UAB, it would be subs=(UAB*) # These subjects should be in $base_dir, so plan accordingly. subs =( <glob to get the names of all the subjects> ) pid = \" ${ subs [ $SLURM_ARRAY_TASK_ID ] } \" # Run heudiconv heudiconv -s $pid -d <path/to/find/all/subject/dicom/files> -o $base_dir /nifti -f <path/to/heuristic> -c dcm2niix -b --overwrite # change the permissions of all of the files in the BIDS directory to have user and group write permissions find $base_dir /nifti/sub- ${ pid //_ } -exec chmod ug+w {} \\; find $base_dir /nifti/.heudiconv/ ${ pid //_ } -exec chmod ug+w {} \\;","title":"Array Job"},{"location":"analysis/bids/practical_heudiconv/","text":"Practical HeuDiConv Example \u00b6 HeuDiConv \u00b6 The tool we use for automatic conversion is HeuDiConv , a heuristic-based dicom converter. This tool is packaged as a Python library, and so in order to have access to it, you will need to create an Anaconda environment and install both HeuDiConv as well as dcm2niix, the actual dicom conversion engine. You can do this process manually through the following commands module load Anaconda3/2020.11 conda create -n bids conda activate bids pip install heudiconv == 0 .9.0 conda install -c conda-forge dcm2niix Or, you can go to the example scripts page , copy the environment creation script there to a .sh file, and then submit it as a batch job. Initial Folder Structure \u00b6 For this example, the dataset will be named D01 , and its parent directory will be /data/project/genlab/datasets to mimic a generic project directory found on Cheaha. When running this tool, be sure to change any paths and folder or subject names to match your dataset. For this walkthrough and in the example scripts, we assume an single session initial folder structure that looks like: D01/ \u2514\u2500\u2500 dicoms/ \u251c\u2500\u2500 participant01/ \u2502 \u251c\u2500\u2500 scan-01/ \u2502 \u2502 \u2514\u2500\u2500 dicom files \u2502 \u251c\u2500\u2500 scan-02/ \u2502 \u2502 \u2514\u2500\u2500 dicom files \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 participant02/ \u2502 \u251c\u2500\u2500 scan-01/ \u2502 \u2502 \u2514\u2500\u2500 dicom files \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 ... The raw dicoms are all stored in the D01/dicoms folder and are organized by participant and by scan. If multiple sessions were acquired for each participant, those sessions would be separated under the participant directory. The example session has the following scan types: 1 T1w and 1 T2w 2 multiband resting state BOLDS 1 multiband emotion recognition BOLD named Emotion 2 two multiband diffusion scans A pair of spin-echo fieldmaps A folder with those scans could look like the following: Every multiband scan will have a corresponding SBRef scan that will also need to be accounted for in the key. Step 1: Generate Scan Info \u00b6 Note Remember, Step 1 only needs to be done once to generate the base heuristic and the scan parameters for key matching. The same heuristic can be used for every participant as long as the scan parameters are not changed. The first step is to generate the scan info to match to. We can assign our dataset directory path to BASE_DIR for to make the command easier to type and more succinct. # set the base dataset directory BASE_DIR = /data/project/genlab/datasets/D01 heudiconv -s S101 -ss 01 -d $BASE_DIR /dicom/ { subject } /ses- { session } /*/*.dcm -o $BASE_DIR /nifti -f convertall -c none --overwrite Step 2: Example Heuristic \u00b6 Anatomicals \u00b6 We have one T1w and one T2w scan, both of which have raw and normalized versions. In our case, we only want to convert the normalized versions. Our key for the anatomicals will be basic, only including the subject and session as variable. The keys will look like: t1 = create_key ( 'sub- {subject} / {session} /anat/sub- {subject} _ {session} _T1w' ) t2 = create_key ( 'sub- {subject} / {session} /anat/sub- {subject} _ {session} _T2w' ) Next, we can determine the if statements for associating the keys with the info dictionary. Since we only want to use one T1w and one T2w, we can just assign the series ID directly to the info dictionary. We will match on the number of acquired slices, the T?w portion of the protocol name to differentiate between T1w and T2w, and 'NORM' in the image_type so that we choose the normalized scans. These if statements that go in the association loop will look like: if ( s . dim3 == 208 ) and ( 'T1w' in s . protocol_name ) and ( 'NORM' in s . image_type ): info [ t1 ] = [ s . series_id ] if ( s . dim3 == 208 ) and ( 'T2w' in s . protocol_name ) and ( 'NORM' in s . image_type ): info [ t2 ] = [ s . series_id ] It is possible to use multiple T1w and T2w scans, although the keys and association statements would need to be amended to include run information. Examples of this can be seen in the Functionals , Field Maps , and Diffusion sections. Field Maps \u00b6 We have two field maps taken in the AP and PA directions. In order to create a sufficient key, we will need to add the direction information to the key and association sections. Additionally, we can add run information in case some subjects have multiple fieldmaps. Our key for Spin Echo field maps will be: fmap = create_key ( 'sub- {subject} / {session} /fmap/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _epi' ) Since we are accounting for the possiblity of multiple field maps in the same direction, we will use the append method instead of direct assignment to the info dictionary. The field map association statement will look like: if ( s . dim4 == 3 ) and ( 'SpinEchoFieldMap_AP' in s . protocol_name ): info [ fmap ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 3 ) and ( 'SpinEchoFieldMap_PA' in s . protocol_name ): info [ fmap ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) We chose to match on the fact each field map has 3 volumes and contains SpinEchoFieldMap in the protocol_name. There is a split based on which direction the field map was acquired in which changes the dir field. Functionals \u00b6 We have multiple resting state scans as well as an emotion recognition task scan. We will create separate keys and association statements for both of these types of scans. Because there are multiple resting state scans acquired in multiple directions, we will include direction and run information in the rest key. Additionally, because these are multiband scans, there are SBRef volumes associated with both scan types. An SBRef key should be made alongside each BOLD scan type. rest = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-rest_dir- {dir} _run- {item:01d} _bold' ) rest_sbref = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-rest_dir- {dir} _run- {item:01d} _sbref' ) emotion = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-Emotion_run- {item:01d} _bold' ) emotion_sbref = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-Emotion_run- {item:01d} _sbref' ) You can see that the only difference between the BOLD scans and their SBRef keys is that the bold tag at the end of the scan has been changed to sbref . The rest of the name should be exactly the same. In the same way as the field maps, we will include run number for both rest and Emotion keys and direction information for the rest key and association statements. # match REST scans and their SBRefs if ( s . dim4 == 420 ) and ( 'REST' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ rest ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 420 ) and ( 'REST' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ rest ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) if ( s . dim4 == 1 ) and ( 'REST' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ rest_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 1 ) and ( 'REST' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ rest_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match Emotion scans and their SBRefs if ( s . dim4 == 176 ) and ( 'EMOTION' in s . dcm_dir_name ): info [ emotion ] . append ({ 'item' : s . series_id }) if ( s . dim4 == 1 ) and ( 'Emotion' in s . dcm_dir_name ) and ( 'SBRef' in s . dcm_dir_name ): info [ emotion_sbref ] . append ({ 'item' : s . series_id }) For resting state scans, we matched on having 'REST' in the name and the direction the scan was acquired in. We also matched based on the number of volumes to differentiate between the BOLD scans and their SBRefs. The same thing was done for the Emotion scan and its SBRef minus the direction information. Diffusion \u00b6 The diffusion block looks very similar to the functional block since we are adding both direction and run number to the key. Again, since the diffusion scans are also multiband, there will be SBRef volumes to convert as well. These SBrefs will have the same sbref tag at the end that the functional SBRefs had, but are differentiated by being stored in the dwi output directory with the diffusion scans. dwi = create_key ( 'sub- {subject} / {session} /dwi/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _dwi' ) dwi_sbref = create_key ( 'sub- {subject} / {session} /dwi/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _sbref' ) The key association portion will also look similar to the functional section, substituting in diffusion scan information where necessary. Since we only have one overall type of diffusion scan (as opposed to task and rest being different for functionals), we will match on the 'dMRI' in the name as well as the direction. # match full diffusion scans including direction if ( s . dim4 == 99 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ dwi ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 99 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ dwi ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match diffusion SBRef including direction to match the full dwi # scan names if ( s . dim4 == 1 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ dwi_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 1 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ dwi_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) These block together form the full heuristic file we will use for sorting these data into BIDS format.The full heuristic file for this example, including the matching criteria, can be seen below: import os def create_key ( template , outtype = ( 'nii.gz' ,), annotation_classes = None ): if template is None or not template : raise ValueError ( 'Template must be a valid format string' ) return template , outtype , annotation_classes def infotodict ( seqinfo ): \"\"\"Heuristic evaluator for determining which runs belong where allowed template fields - follow python string module: item: index within category subject: participant id seqitem: run number during scanning subindex: sub index within group \"\"\" ########################## Scan Keys ############################## t1 = create_key ( 'sub- {subject} / {session} /anat/sub- {subject} _ {session} _T1w' ) t2 = create_key ( 'sub- {subject} / {session} /anat/sub- {subject} _ {session} _T2w' ) fmap = create_key ( 'sub- {subject} / {session} /fmap/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _epi' ) rest = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-rest_dir- {dir} _run- {item:01d} _bold' ) rest_sbref = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-rest_dir- {dir} _run- {item:01d} _sbref' ) emotion = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-Emotion_run- {item:01d} _bold' ) emotion_sbref = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-Emotion_run- {item:01d} _sbref' ) dwi = create_key ( 'sub- {subject} / {session} /dwi/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _dwi' ) dwi_sbref = create_key ( 'sub- {subject} / {session} /dwi/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _sbref' ) info = { t1 :[], t2 :[], fmap :[], rest :[], emotion :[], rest_sbref :[], emotion_sbref :[], dwi :[], dwi_sbref :[]} ################# Associate Keys with Scans ####################### for idx , s in enumerate ( seqinfo ): # match T1 and T2 scans. No appending due to only wanting a single # of each type if ( s . dim3 == 208 ) and ( 'T1w' in s . protocol_name ) and ( 'NORM' in s . image_type ): info [ t1 ] = [ s . series_id ] if ( s . dim3 == 208 ) and ( 'T2w' in s . protocol_name ) and ( 'NORM' in s . image_type ): info [ t2 ] = [ s . series_id ] # match phase-encoded fieldmaps including direction if ( s . dim4 == 3 ) and ( 'SpinEchoFieldMap_AP' in s . protocol_name ): info [ fmap ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 3 ) and ( 'SpinEchoFieldMap_PA' in s . protocol_name ): info [ fmap ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match full functional scans including direction for the REST scans if ( s . dim4 == 420 ) and ( 'REST' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ rest ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 420 ) and ( 'REST' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ rest ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) if ( s . dim4 == 1 ) and ( 'REST' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ rest_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 1 ) and ( 'REST' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ rest_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match functional SBRef including direction to match the full functional scan names if ( s . dim4 == 176 ) and ( 'EMOTION' in s . dcm_dir_name ): info [ emotion ] . append ({ 'item' : s . series_id }) if ( s . dim4 == 1 ) and ( 'EMOTION' in s . dcm_dir_name ): info [ emotion_sbref ] . append ({ 'item' : s . series_id }) # match full diffusion scans including direction if ( s . dim4 == 99 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ dwi ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 99 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ dwi ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match diffusion SBRef including direction to match the full dwi # scan names if ( s . dim4 == 1 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ dwi_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 1 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ dwi_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) return info Step 3: BIDS Conversion \u00b6 At this point, the heuristic is set up, and the last step is performing the sort. The command looks very similar to that in Step 1, with a couple of changes. The command we use here is: # Give a path to the dataset directory that we can use BASE_DIR = /data/project/genlab/datasets/D01 heudiconv -s S101 -ss 01 -d $BASE_DIR /dicom/ { subject } /ses- { session } /*/*.dcm -o $BASE_DIR /nifti -f $BASE_DIR /heuristic.py -c dcm2niix -b --overwrite The only options that have changed are: -f : changed from convertall to the path to the heuristic -c : changed from none to dcm2niix -b : added Step 4: Clean Up \u00b6 After BIDS conversion, there are a couple of things that need to be done as cleanup: changing permissions for your images and associating any fieldmaps with functional and diffusion images. File Permissions \u00b6 By default, HeuDiConv makes all output files read-only. This causes some issues with some software, such as fmriprep, which need write permissions on the json and images files to operate correctly. Changing file permissions is straightforward: # change the permissions of all of the files in the BIDS directory to have user and group write permissions find $base_dir /nifti/<BIDS subject name> -exec chmod ug+w {} \\; find $base_dir /nifti/.heudiconv/<BIDS subject name> -exec chmod ug+w {} \\; These lines are included at the end of the example scripts and will add user and group write permissions for the BIDS files. Associating FieldMaps with Func and DWI scans \u00b6 Some preprocessing pipelines will automatically perform distortion correction on EPI images using fieldmaps, if you have acquired them. However, there's no metadata automatically created associating fieldmaps with the EPI scans they are used to correct, and so needs to be added manually. You do this by adding the \"IntendedFor\" field to the json sidecars. An example of this field can be seen below: \"IntendedFor\" :[ \"dwi/sub-S01_dir-AP_run-1_dwi.nii.gz\" , \"func/sub-S01_task-rest_dir-AP_run-1_bold.nii.gz\" , \"func/sub-S01_task-rest_dir-PA_run-2_bold.nii.gz\" ], The names of the files should change to match your BIDS files. If you have collected a single set of fieldmaps (e.g. AP and PA spin echo fieldmaps), the IntendedFor fields should be the same for both of them. If you have collected multiple sets through the same scan session, you will need to choose which scans each individual fieldmap or fieldmap set will be intended for. An example use case for this would be reaquiring field maps after letting the participant out of the scanner for a break in the middle of a session. The reacquired field maps would be intended for EPI images only acquired after the break while the original field maps would be intended for scans acquired before the break. Each EPI scan should only be named in an IntendedFor field for a single fieldmap or fieldmap set. BIDS Outputs \u00b6 Once the function finishes, there will a subject and session path in the $BASE_DIR/nifti directory that leads to the BIDS converted files. For this example, there will be anat , fmap , func , and dwi folders. The output file structure for these folders can be seen below. D01/nifti/sub-S101/ses-01/anat: D01/nifti/sub-S101/ses-01/fmap: D01/nifti/sub-S101/ses-01/func: D01/nifti/sub-S101/ses-01/dwi:","title":"Practical HeuDiConv Example"},{"location":"analysis/bids/practical_heudiconv/#practical-heudiconv-example","text":"","title":"Practical HeuDiConv Example"},{"location":"analysis/bids/practical_heudiconv/#heudiconv","text":"The tool we use for automatic conversion is HeuDiConv , a heuristic-based dicom converter. This tool is packaged as a Python library, and so in order to have access to it, you will need to create an Anaconda environment and install both HeuDiConv as well as dcm2niix, the actual dicom conversion engine. You can do this process manually through the following commands module load Anaconda3/2020.11 conda create -n bids conda activate bids pip install heudiconv == 0 .9.0 conda install -c conda-forge dcm2niix Or, you can go to the example scripts page , copy the environment creation script there to a .sh file, and then submit it as a batch job.","title":"HeuDiConv"},{"location":"analysis/bids/practical_heudiconv/#initial-folder-structure","text":"For this example, the dataset will be named D01 , and its parent directory will be /data/project/genlab/datasets to mimic a generic project directory found on Cheaha. When running this tool, be sure to change any paths and folder or subject names to match your dataset. For this walkthrough and in the example scripts, we assume an single session initial folder structure that looks like: D01/ \u2514\u2500\u2500 dicoms/ \u251c\u2500\u2500 participant01/ \u2502 \u251c\u2500\u2500 scan-01/ \u2502 \u2502 \u2514\u2500\u2500 dicom files \u2502 \u251c\u2500\u2500 scan-02/ \u2502 \u2502 \u2514\u2500\u2500 dicom files \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 participant02/ \u2502 \u251c\u2500\u2500 scan-01/ \u2502 \u2502 \u2514\u2500\u2500 dicom files \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 ... The raw dicoms are all stored in the D01/dicoms folder and are organized by participant and by scan. If multiple sessions were acquired for each participant, those sessions would be separated under the participant directory. The example session has the following scan types: 1 T1w and 1 T2w 2 multiband resting state BOLDS 1 multiband emotion recognition BOLD named Emotion 2 two multiband diffusion scans A pair of spin-echo fieldmaps A folder with those scans could look like the following: Every multiband scan will have a corresponding SBRef scan that will also need to be accounted for in the key.","title":"Initial Folder Structure"},{"location":"analysis/bids/practical_heudiconv/#step-1-generate-scan-info","text":"Note Remember, Step 1 only needs to be done once to generate the base heuristic and the scan parameters for key matching. The same heuristic can be used for every participant as long as the scan parameters are not changed. The first step is to generate the scan info to match to. We can assign our dataset directory path to BASE_DIR for to make the command easier to type and more succinct. # set the base dataset directory BASE_DIR = /data/project/genlab/datasets/D01 heudiconv -s S101 -ss 01 -d $BASE_DIR /dicom/ { subject } /ses- { session } /*/*.dcm -o $BASE_DIR /nifti -f convertall -c none --overwrite","title":"Step 1: Generate Scan Info"},{"location":"analysis/bids/practical_heudiconv/#step-2-example-heuristic","text":"","title":"Step 2: Example Heuristic"},{"location":"analysis/bids/practical_heudiconv/#anatomicals","text":"We have one T1w and one T2w scan, both of which have raw and normalized versions. In our case, we only want to convert the normalized versions. Our key for the anatomicals will be basic, only including the subject and session as variable. The keys will look like: t1 = create_key ( 'sub- {subject} / {session} /anat/sub- {subject} _ {session} _T1w' ) t2 = create_key ( 'sub- {subject} / {session} /anat/sub- {subject} _ {session} _T2w' ) Next, we can determine the if statements for associating the keys with the info dictionary. Since we only want to use one T1w and one T2w, we can just assign the series ID directly to the info dictionary. We will match on the number of acquired slices, the T?w portion of the protocol name to differentiate between T1w and T2w, and 'NORM' in the image_type so that we choose the normalized scans. These if statements that go in the association loop will look like: if ( s . dim3 == 208 ) and ( 'T1w' in s . protocol_name ) and ( 'NORM' in s . image_type ): info [ t1 ] = [ s . series_id ] if ( s . dim3 == 208 ) and ( 'T2w' in s . protocol_name ) and ( 'NORM' in s . image_type ): info [ t2 ] = [ s . series_id ] It is possible to use multiple T1w and T2w scans, although the keys and association statements would need to be amended to include run information. Examples of this can be seen in the Functionals , Field Maps , and Diffusion sections.","title":"Anatomicals"},{"location":"analysis/bids/practical_heudiconv/#field-maps","text":"We have two field maps taken in the AP and PA directions. In order to create a sufficient key, we will need to add the direction information to the key and association sections. Additionally, we can add run information in case some subjects have multiple fieldmaps. Our key for Spin Echo field maps will be: fmap = create_key ( 'sub- {subject} / {session} /fmap/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _epi' ) Since we are accounting for the possiblity of multiple field maps in the same direction, we will use the append method instead of direct assignment to the info dictionary. The field map association statement will look like: if ( s . dim4 == 3 ) and ( 'SpinEchoFieldMap_AP' in s . protocol_name ): info [ fmap ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 3 ) and ( 'SpinEchoFieldMap_PA' in s . protocol_name ): info [ fmap ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) We chose to match on the fact each field map has 3 volumes and contains SpinEchoFieldMap in the protocol_name. There is a split based on which direction the field map was acquired in which changes the dir field.","title":"Field Maps"},{"location":"analysis/bids/practical_heudiconv/#functionals","text":"We have multiple resting state scans as well as an emotion recognition task scan. We will create separate keys and association statements for both of these types of scans. Because there are multiple resting state scans acquired in multiple directions, we will include direction and run information in the rest key. Additionally, because these are multiband scans, there are SBRef volumes associated with both scan types. An SBRef key should be made alongside each BOLD scan type. rest = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-rest_dir- {dir} _run- {item:01d} _bold' ) rest_sbref = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-rest_dir- {dir} _run- {item:01d} _sbref' ) emotion = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-Emotion_run- {item:01d} _bold' ) emotion_sbref = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-Emotion_run- {item:01d} _sbref' ) You can see that the only difference between the BOLD scans and their SBRef keys is that the bold tag at the end of the scan has been changed to sbref . The rest of the name should be exactly the same. In the same way as the field maps, we will include run number for both rest and Emotion keys and direction information for the rest key and association statements. # match REST scans and their SBRefs if ( s . dim4 == 420 ) and ( 'REST' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ rest ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 420 ) and ( 'REST' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ rest ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) if ( s . dim4 == 1 ) and ( 'REST' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ rest_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 1 ) and ( 'REST' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ rest_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match Emotion scans and their SBRefs if ( s . dim4 == 176 ) and ( 'EMOTION' in s . dcm_dir_name ): info [ emotion ] . append ({ 'item' : s . series_id }) if ( s . dim4 == 1 ) and ( 'Emotion' in s . dcm_dir_name ) and ( 'SBRef' in s . dcm_dir_name ): info [ emotion_sbref ] . append ({ 'item' : s . series_id }) For resting state scans, we matched on having 'REST' in the name and the direction the scan was acquired in. We also matched based on the number of volumes to differentiate between the BOLD scans and their SBRefs. The same thing was done for the Emotion scan and its SBRef minus the direction information.","title":"Functionals"},{"location":"analysis/bids/practical_heudiconv/#diffusion","text":"The diffusion block looks very similar to the functional block since we are adding both direction and run number to the key. Again, since the diffusion scans are also multiband, there will be SBRef volumes to convert as well. These SBrefs will have the same sbref tag at the end that the functional SBRefs had, but are differentiated by being stored in the dwi output directory with the diffusion scans. dwi = create_key ( 'sub- {subject} / {session} /dwi/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _dwi' ) dwi_sbref = create_key ( 'sub- {subject} / {session} /dwi/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _sbref' ) The key association portion will also look similar to the functional section, substituting in diffusion scan information where necessary. Since we only have one overall type of diffusion scan (as opposed to task and rest being different for functionals), we will match on the 'dMRI' in the name as well as the direction. # match full diffusion scans including direction if ( s . dim4 == 99 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ dwi ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 99 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ dwi ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match diffusion SBRef including direction to match the full dwi # scan names if ( s . dim4 == 1 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ dwi_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 1 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ dwi_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) These block together form the full heuristic file we will use for sorting these data into BIDS format.The full heuristic file for this example, including the matching criteria, can be seen below: import os def create_key ( template , outtype = ( 'nii.gz' ,), annotation_classes = None ): if template is None or not template : raise ValueError ( 'Template must be a valid format string' ) return template , outtype , annotation_classes def infotodict ( seqinfo ): \"\"\"Heuristic evaluator for determining which runs belong where allowed template fields - follow python string module: item: index within category subject: participant id seqitem: run number during scanning subindex: sub index within group \"\"\" ########################## Scan Keys ############################## t1 = create_key ( 'sub- {subject} / {session} /anat/sub- {subject} _ {session} _T1w' ) t2 = create_key ( 'sub- {subject} / {session} /anat/sub- {subject} _ {session} _T2w' ) fmap = create_key ( 'sub- {subject} / {session} /fmap/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _epi' ) rest = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-rest_dir- {dir} _run- {item:01d} _bold' ) rest_sbref = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-rest_dir- {dir} _run- {item:01d} _sbref' ) emotion = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-Emotion_run- {item:01d} _bold' ) emotion_sbref = create_key ( 'sub- {subject} / {session} /func/sub- {subject} _ {session} _task-Emotion_run- {item:01d} _sbref' ) dwi = create_key ( 'sub- {subject} / {session} /dwi/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _dwi' ) dwi_sbref = create_key ( 'sub- {subject} / {session} /dwi/sub- {subject} _ {session} _dir- {dir} _run- {item:01d} _sbref' ) info = { t1 :[], t2 :[], fmap :[], rest :[], emotion :[], rest_sbref :[], emotion_sbref :[], dwi :[], dwi_sbref :[]} ################# Associate Keys with Scans ####################### for idx , s in enumerate ( seqinfo ): # match T1 and T2 scans. No appending due to only wanting a single # of each type if ( s . dim3 == 208 ) and ( 'T1w' in s . protocol_name ) and ( 'NORM' in s . image_type ): info [ t1 ] = [ s . series_id ] if ( s . dim3 == 208 ) and ( 'T2w' in s . protocol_name ) and ( 'NORM' in s . image_type ): info [ t2 ] = [ s . series_id ] # match phase-encoded fieldmaps including direction if ( s . dim4 == 3 ) and ( 'SpinEchoFieldMap_AP' in s . protocol_name ): info [ fmap ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 3 ) and ( 'SpinEchoFieldMap_PA' in s . protocol_name ): info [ fmap ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match full functional scans including direction for the REST scans if ( s . dim4 == 420 ) and ( 'REST' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ rest ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 420 ) and ( 'REST' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ rest ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) if ( s . dim4 == 1 ) and ( 'REST' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ rest_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 1 ) and ( 'REST' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ rest_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match functional SBRef including direction to match the full functional scan names if ( s . dim4 == 176 ) and ( 'EMOTION' in s . dcm_dir_name ): info [ emotion ] . append ({ 'item' : s . series_id }) if ( s . dim4 == 1 ) and ( 'EMOTION' in s . dcm_dir_name ): info [ emotion_sbref ] . append ({ 'item' : s . series_id }) # match full diffusion scans including direction if ( s . dim4 == 99 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ dwi ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 99 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ dwi ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) # match diffusion SBRef including direction to match the full dwi # scan names if ( s . dim4 == 1 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'AP' in s . dcm_dir_name ): info [ dwi_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'AP' }) if ( s . dim4 == 1 ) and ( 'dMRI' in s . dcm_dir_name ) and ( 'PA' in s . dcm_dir_name ): info [ dwi_sbref ] . append ({ 'item' : s . series_id , 'dir' : 'PA' }) return info","title":"Diffusion"},{"location":"analysis/bids/practical_heudiconv/#step-3-bids-conversion","text":"At this point, the heuristic is set up, and the last step is performing the sort. The command looks very similar to that in Step 1, with a couple of changes. The command we use here is: # Give a path to the dataset directory that we can use BASE_DIR = /data/project/genlab/datasets/D01 heudiconv -s S101 -ss 01 -d $BASE_DIR /dicom/ { subject } /ses- { session } /*/*.dcm -o $BASE_DIR /nifti -f $BASE_DIR /heuristic.py -c dcm2niix -b --overwrite The only options that have changed are: -f : changed from convertall to the path to the heuristic -c : changed from none to dcm2niix -b : added","title":"Step 3: BIDS Conversion"},{"location":"analysis/bids/practical_heudiconv/#step-4-clean-up","text":"After BIDS conversion, there are a couple of things that need to be done as cleanup: changing permissions for your images and associating any fieldmaps with functional and diffusion images.","title":"Step 4: Clean Up"},{"location":"analysis/bids/practical_heudiconv/#file-permissions","text":"By default, HeuDiConv makes all output files read-only. This causes some issues with some software, such as fmriprep, which need write permissions on the json and images files to operate correctly. Changing file permissions is straightforward: # change the permissions of all of the files in the BIDS directory to have user and group write permissions find $base_dir /nifti/<BIDS subject name> -exec chmod ug+w {} \\; find $base_dir /nifti/.heudiconv/<BIDS subject name> -exec chmod ug+w {} \\; These lines are included at the end of the example scripts and will add user and group write permissions for the BIDS files.","title":"File Permissions"},{"location":"analysis/bids/practical_heudiconv/#associating-fieldmaps-with-func-and-dwi-scans","text":"Some preprocessing pipelines will automatically perform distortion correction on EPI images using fieldmaps, if you have acquired them. However, there's no metadata automatically created associating fieldmaps with the EPI scans they are used to correct, and so needs to be added manually. You do this by adding the \"IntendedFor\" field to the json sidecars. An example of this field can be seen below: \"IntendedFor\" :[ \"dwi/sub-S01_dir-AP_run-1_dwi.nii.gz\" , \"func/sub-S01_task-rest_dir-AP_run-1_bold.nii.gz\" , \"func/sub-S01_task-rest_dir-PA_run-2_bold.nii.gz\" ], The names of the files should change to match your BIDS files. If you have collected a single set of fieldmaps (e.g. AP and PA spin echo fieldmaps), the IntendedFor fields should be the same for both of them. If you have collected multiple sets through the same scan session, you will need to choose which scans each individual fieldmap or fieldmap set will be intended for. An example use case for this would be reaquiring field maps after letting the participant out of the scanner for a break in the middle of a session. The reacquired field maps would be intended for EPI images only acquired after the break while the original field maps would be intended for scans acquired before the break. Each EPI scan should only be named in an IntendedFor field for a single fieldmap or fieldmap set.","title":"Associating FieldMaps with Func and DWI scans"},{"location":"analysis/bids/practical_heudiconv/#bids-outputs","text":"Once the function finishes, there will a subject and session path in the $BASE_DIR/nifti directory that leads to the BIDS converted files. For this example, there will be anat , fmap , func , and dwi folders. The output file structure for these folders can be seen below. D01/nifti/sub-S101/ses-01/anat: D01/nifti/sub-S101/ses-01/fmap: D01/nifti/sub-S101/ses-01/func: D01/nifti/sub-S101/ses-01/dwi:","title":"BIDS Outputs"},{"location":"analysis/bids/principles/","text":"Basic BIDS Principles \u00b6 This document will give a short and sweet introduction to the basic naming system for BIDS-compliant niftis and their JSON sidecars as well as example folder structures. For a much more comprehensive introduction to the BIDS structure, see the BIDS docs File Name Structure \u00b6 File names are made from combinations of key-value pairs strung together. Some key-value pairs are optional based on the experimental design, but others, such as subject name and task type for fMRI scans, are not. Key-value pairs are linked with hyphens while underscores separate each pair. For example, if a participant with ID TS001 had a resting state scan, the portion of the scan name telling us such would read sub-TS001_task-rest . Since both - and _ are protected characters in the BIDS naming system, they cannot be used in participant or scan IDs and should be removed during BIDS conversion. Conversion tools can take care of that automatically, but if you choose to manually convert to BIDS, you will need to include this step in your pipeline. A summary of all possible key-value pairs that make up a BIDS name as well as whether they are optional or required can be found in the entity table . JSON sidecars \u00b6 Each nifti file in your study should also have an accompanying JSON file that contains relevant metadata from the DICOM files that can be lost when converting to nifti as well as pertinent information about the participant and study. The accompanying JSON files can be complex and tedious to create manually. If you choose to create custom JSON sidecars, it is imperative you read about the associated required metadata fields for each type of scan in your study. Those descriptions and naming guidelines for MRI data can be found in the BIDS MRI naming guide . It is highly recommended to use a semi-automatic DICOM to BIDS converter to generate both the nifti and JSON files. Recommended converters are dcm2bids and heudiconv . A general guide to using heudiconv can be found in this documentation as well. Example Name Formats \u00b6 For the following examples, any key-value pain in [] is optional in the name. Replace entries in <> with corresponding information for the scan. Some values in <> must be chosen from a given list from the BIDS site. For example, a T1w anatomical image must have the \\ field specified as T1w, not T1. These examples are not exhaustive but include some more common use cases. Links to more examples as well as a complete list and explanation of key-value pairs are given in each section. Common Keys \u00b6 All common keys listed here can be used for multiple image types, but none are required to be included except in specific cases. However, these can be included to further describe the scan to other researchers without having to read metadata from the JSON files. Key Description Example Values ses Session number the scan belongs to. If the subject ses-01, ses-02 dir Image phase-encoding direction dir-AP, dir-LR run Distinguishes between scans with the same acquisition and direction run-1, run-2 acq Allows the user to distinguish between parameter sets used to acquire the same image modality acq-highres, acq-lowres Anatomical \u00b6 Names for general anatomical nifti and json files can be found here. These include T1w, T2w, MP2RAGE, proton density, and others, but not diffusion-weighted or functional data. Also included are naming conventions for binary defacing masks, if defacing was performed for your dataset. Defacing is not required, and inclusion of the masks is not required even if defacing was performed. anat/ # Naming structure for general anatomical scans sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>][_rec-<label>][_run-<index>]_<suffix>.json sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>][_rec-<label>][_run-<index>]_<suffix>.nii[.gz] # Naming structure for binary mask used during potential defacing sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>][_rec-<label>][_run-<index>][_mod-<label>]_defacemask.json sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>][_rec-<label>][_run-<index>][_mod-<label>]_defacemask.nii[.gz] A more complete list of anatomical names and key-value pair explanations can be found here . Functional (Task and Resting) \u00b6 Currently, the supported contrasts for task and resting imaging data are BOLD and cerebral blood volume (CBV). func/ # BOLD contrast naming scheme sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_bold.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_bold.nii[.gz] # CBV contrast naming scheme sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_cbv.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_cbv.nii[.gz] # Single-band reference images collected before multi-band sequences sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_sbref.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_sbref.nii[.gz] # Naming scheme for description of event timing during tasks scans sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>]_events.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>]_events.tsv # Naming scheme for physio data collected and stored as tsv sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_recording-<label>]_physio.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_recording-<label>]_physio.tsv.gz The task key followed by the task name is always required for BOLD and CBV scans. For resting-state scans, the appropriate key-value pair is task-rest . For multiple resting state or multiple of the same task, use the run and dir keys to differentiate them. Task event file names should match the scan name exactly, except replacing _bold.nii.gz with _events.tsv. As always, the json file name should match the events.tsv name. A more complete list of functional names and key-value pair explanations can be found here . Diffusion \u00b6 Currently, the only supported diffusion imaging types are diffusion-weighted (dwi), and their corresponding single-band reference (sbref) images, if multi-band was used to collect the diffusion data. dwi/ # bvec and bval outputs from converting to nifti sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_dwi.bval sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_dwi.bvec # Diffusion scan naming scheme sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_dwi.json sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_dwi.nii[.gz] # SBRef naming scheme sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_sbref.json sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_sbref.nii[.gz] bvec and bval files MUST follow the FSL format. A more complete list of diffusion names and key-value pair explanations as well as an explanation of the FSL format for bvec and bval files can be found here . Fieldmap \u00b6 Multiple types of phasemaps can be stored using the BIDS data structure. These include phase-difference maps, two phase maps, direct field maps, and phase-encoded polar fieldmaps. Which type of fieldmap you acquire for your dataset will determine the suffix at the end of the file name. fmap/ # Phase-difference maps sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude1.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude1.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude2.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude2.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phasediff.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phasediff.nii[.gz] # Two phase maps sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude1.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude1.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude2.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude2.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phase1.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phase1.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phase2.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phase2.nii[.gz] # Direct fieldmap sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_fieldmap.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_fieldmap.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude.nii[.gz] # Multiple phase encoded directions (AP/PA; LR/RL) sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>]_dir-<label>[_run-<index>]_epi.json sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>]_dir-<label>[_run-<index>]_epi.nii[.gz] For multiple phase encoded directions, the dir key-pair must be included in the name. A more complete list of field map names and key-value pair explanations as well as an explanation of the FSL format for bvec and bval files can be found here . BIDS Validation \u00b6 After you convert a dataset to BIDS, you can validate it using a couple of tools. First, there is an online validator at https://bids-standard.github.io/bids-validator/ . Select your BIDS output dataset folder and it will determine if anything is not BIDS compliant. It does not upload any data, so it is safe for PHI. fmriprep, as its first step, also will perform BIDS validation on any subject it is performed on. This can be disabled as a setting if you've already used the online tool. It's a good idea to always validate the dataset after conversion just in case something needs to be fixed.","title":"Basic BIDS Principles"},{"location":"analysis/bids/principles/#basic-bids-principles","text":"This document will give a short and sweet introduction to the basic naming system for BIDS-compliant niftis and their JSON sidecars as well as example folder structures. For a much more comprehensive introduction to the BIDS structure, see the BIDS docs","title":"Basic BIDS Principles"},{"location":"analysis/bids/principles/#file-name-structure","text":"File names are made from combinations of key-value pairs strung together. Some key-value pairs are optional based on the experimental design, but others, such as subject name and task type for fMRI scans, are not. Key-value pairs are linked with hyphens while underscores separate each pair. For example, if a participant with ID TS001 had a resting state scan, the portion of the scan name telling us such would read sub-TS001_task-rest . Since both - and _ are protected characters in the BIDS naming system, they cannot be used in participant or scan IDs and should be removed during BIDS conversion. Conversion tools can take care of that automatically, but if you choose to manually convert to BIDS, you will need to include this step in your pipeline. A summary of all possible key-value pairs that make up a BIDS name as well as whether they are optional or required can be found in the entity table .","title":"File Name Structure"},{"location":"analysis/bids/principles/#json-sidecars","text":"Each nifti file in your study should also have an accompanying JSON file that contains relevant metadata from the DICOM files that can be lost when converting to nifti as well as pertinent information about the participant and study. The accompanying JSON files can be complex and tedious to create manually. If you choose to create custom JSON sidecars, it is imperative you read about the associated required metadata fields for each type of scan in your study. Those descriptions and naming guidelines for MRI data can be found in the BIDS MRI naming guide . It is highly recommended to use a semi-automatic DICOM to BIDS converter to generate both the nifti and JSON files. Recommended converters are dcm2bids and heudiconv . A general guide to using heudiconv can be found in this documentation as well.","title":"JSON sidecars"},{"location":"analysis/bids/principles/#example-name-formats","text":"For the following examples, any key-value pain in [] is optional in the name. Replace entries in <> with corresponding information for the scan. Some values in <> must be chosen from a given list from the BIDS site. For example, a T1w anatomical image must have the \\ field specified as T1w, not T1. These examples are not exhaustive but include some more common use cases. Links to more examples as well as a complete list and explanation of key-value pairs are given in each section.","title":"Example Name Formats"},{"location":"analysis/bids/principles/#common-keys","text":"All common keys listed here can be used for multiple image types, but none are required to be included except in specific cases. However, these can be included to further describe the scan to other researchers without having to read metadata from the JSON files. Key Description Example Values ses Session number the scan belongs to. If the subject ses-01, ses-02 dir Image phase-encoding direction dir-AP, dir-LR run Distinguishes between scans with the same acquisition and direction run-1, run-2 acq Allows the user to distinguish between parameter sets used to acquire the same image modality acq-highres, acq-lowres","title":"Common Keys"},{"location":"analysis/bids/principles/#anatomical","text":"Names for general anatomical nifti and json files can be found here. These include T1w, T2w, MP2RAGE, proton density, and others, but not diffusion-weighted or functional data. Also included are naming conventions for binary defacing masks, if defacing was performed for your dataset. Defacing is not required, and inclusion of the masks is not required even if defacing was performed. anat/ # Naming structure for general anatomical scans sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>][_rec-<label>][_run-<index>]_<suffix>.json sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>][_rec-<label>][_run-<index>]_<suffix>.nii[.gz] # Naming structure for binary mask used during potential defacing sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>][_rec-<label>][_run-<index>][_mod-<label>]_defacemask.json sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>][_rec-<label>][_run-<index>][_mod-<label>]_defacemask.nii[.gz] A more complete list of anatomical names and key-value pair explanations can be found here .","title":"Anatomical"},{"location":"analysis/bids/principles/#functional-task-and-resting","text":"Currently, the supported contrasts for task and resting imaging data are BOLD and cerebral blood volume (CBV). func/ # BOLD contrast naming scheme sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_bold.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_bold.nii[.gz] # CBV contrast naming scheme sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_cbv.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_cbv.nii[.gz] # Single-band reference images collected before multi-band sequences sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_sbref.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_echo-<index>][_part-<label>]_sbref.nii[.gz] # Naming scheme for description of event timing during tasks scans sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>]_events.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>]_events.tsv # Naming scheme for physio data collected and stored as tsv sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_recording-<label>]_physio.json sub-<label>[_ses-<label>]_task-<label>[_acq-<label>][_ce-<label>][_rec-<label>][_dir-<label>][_run-<index>][_recording-<label>]_physio.tsv.gz The task key followed by the task name is always required for BOLD and CBV scans. For resting-state scans, the appropriate key-value pair is task-rest . For multiple resting state or multiple of the same task, use the run and dir keys to differentiate them. Task event file names should match the scan name exactly, except replacing _bold.nii.gz with _events.tsv. As always, the json file name should match the events.tsv name. A more complete list of functional names and key-value pair explanations can be found here .","title":"Functional (Task and Resting)"},{"location":"analysis/bids/principles/#diffusion","text":"Currently, the only supported diffusion imaging types are diffusion-weighted (dwi), and their corresponding single-band reference (sbref) images, if multi-band was used to collect the diffusion data. dwi/ # bvec and bval outputs from converting to nifti sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_dwi.bval sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_dwi.bvec # Diffusion scan naming scheme sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_dwi.json sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_dwi.nii[.gz] # SBRef naming scheme sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_sbref.json sub-<label>[_ses-<label>][_acq-<label>][_dir-<label>][_run-<index>][_part-<label>]_sbref.nii[.gz] bvec and bval files MUST follow the FSL format. A more complete list of diffusion names and key-value pair explanations as well as an explanation of the FSL format for bvec and bval files can be found here .","title":"Diffusion"},{"location":"analysis/bids/principles/#fieldmap","text":"Multiple types of phasemaps can be stored using the BIDS data structure. These include phase-difference maps, two phase maps, direct field maps, and phase-encoded polar fieldmaps. Which type of fieldmap you acquire for your dataset will determine the suffix at the end of the file name. fmap/ # Phase-difference maps sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude1.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude1.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude2.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude2.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phasediff.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phasediff.nii[.gz] # Two phase maps sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude1.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude1.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude2.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude2.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phase1.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phase1.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phase2.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_phase2.nii[.gz] # Direct fieldmap sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_fieldmap.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_fieldmap.nii[.gz] sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude.json sub-<label>[_ses-<label>][_acq-<label>][_run-<index>]_magnitude.nii[.gz] # Multiple phase encoded directions (AP/PA; LR/RL) sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>]_dir-<label>[_run-<index>]_epi.json sub-<label>[_ses-<label>][_acq-<label>][_ce-<label>]_dir-<label>[_run-<index>]_epi.nii[.gz] For multiple phase encoded directions, the dir key-pair must be included in the name. A more complete list of field map names and key-value pair explanations as well as an explanation of the FSL format for bvec and bval files can be found here .","title":"Fieldmap"},{"location":"analysis/bids/principles/#bids-validation","text":"After you convert a dataset to BIDS, you can validate it using a couple of tools. First, there is an online validator at https://bids-standard.github.io/bids-validator/ . Select your BIDS output dataset folder and it will determine if anything is not BIDS compliant. It does not upload any data, so it is safe for PHI. fmriprep, as its first step, also will perform BIDS validation on any subject it is performed on. This can be disabled as a setting if you've already used the online tool. It's a good idea to always validate the dataset after conversion just in case something needs to be fixed.","title":"BIDS Validation"},{"location":"analysis/fmriprep/","text":"fmriprep \u00b6 fmriprep is an fMRI preprocessing pipeline designed to provide an easily accessible interface regardless of scan acquisition parameters while requiring little user input. It performs minimal preprocessing, steps generally accepted to be necessary for any fMRI analysis pipeline. These include coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc. In order to run certain steps, it also performs automatic surface reconstruction through FreeSurfer . fmriprep is similar in scope to other minimal preprocessing pipelines like the HCP Pipelines . To perform preprocessing, fmriprep uses tools from a variety of well-known software packages such as FSL , ANTs , AFNI , and the aforementioned FreeSurfer. Which tools are chosen for which steps were determined by the fmriprep creators. The tools used will be updated and changed as newer and better software is available. For full information on fmriprep, please read their ReadTheDocs .","title":"Introduction"},{"location":"analysis/fmriprep/#fmriprep","text":"fmriprep is an fMRI preprocessing pipeline designed to provide an easily accessible interface regardless of scan acquisition parameters while requiring little user input. It performs minimal preprocessing, steps generally accepted to be necessary for any fMRI analysis pipeline. These include coregistration, normalization, unwarping, noise component extraction, segmentation, skullstripping etc. In order to run certain steps, it also performs automatic surface reconstruction through FreeSurfer . fmriprep is similar in scope to other minimal preprocessing pipelines like the HCP Pipelines . To perform preprocessing, fmriprep uses tools from a variety of well-known software packages such as FSL , ANTs , AFNI , and the aforementioned FreeSurfer. Which tools are chosen for which steps were determined by the fmriprep creators. The tools used will be updated and changed as newer and better software is available. For full information on fmriprep, please read their ReadTheDocs .","title":"fmriprep"},{"location":"analysis/fmriprep/fmriprep-scripts/","text":"Example fmriprep Scripts \u00b6 Example Single-Subject Job Script \u00b6 This example script was written to process a single subject P01 from BIDS-formatted dataset D01 stored in $USER_DATA . #!/bin/bash # #SBATCH --job-name=P01-fmriprep #SBATCH --output=$USER_DATA/D01/jobs/out/P01-fmriprep-out.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --partition=medium #SBATCH --time=50:00:00 #SBATCH --mem-per-cpu=5G #SBATCH --mail-type=FAIL # Users should only need to change the dataset_dir and the participant below to run this script. # set the path to the dataset directory. This is the parent to the BIDS-formatted nifti directory. dataset_dir = $USER_DATA /D01 # set the name of the participant participant = P01 # load the module module load rc/fmriprep/20.2.3 # run fmriprep fmriprep --work-dir $dataset_dir /workdir/ \\ --participant-label $participant \\ --output-spaces T1w \\ --fs-license-file $HOME /license.txt \\ --n-cpus 4 \\ --omp-nthreads 4 \\ --cifti-output 91k \\ $dataset_dir /nifti/ \\ $dataset_dir /nifti/derivatives \\ participant The job requests 4 CPUs and 4 GBs of memory per CPU for 50 hours total on the medium partition. The working directory was placed directly underneath the dataset directory The output space of the BOLD images was set to native T1w space as opposed to a normalized template space. The copied FreeSurfer license file was placed in my home directory and referenced in the script. All outputs were requested to be in cifti-space (91k default) The bids_dir , output_dir , and analysis_level were listed in that order after the options. This script can be submitted to the scheduler using sbatch <script.sh> where script.sh is the full path of the script (or just the script name if the terminal working directory contains the script). Example Array Job Script \u00b6 SLURM job arrays are scripts made to easily replicate a job to be performed across multiple inputs (i.e. multiple participants) while not taxing the job scheduler. Read more about SLURM job arrays at their documentation . This example script was written to process all subjects from the participants.tsv file in BIDS-formatted dataset D01 . #!/bin/bash # #SBATCH --job-name=fmriprep-%a #SBATCH --output=fmriprep-%A-%a.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --partition=medium #SBATCH --time=50:00:00 #SBATCH --mem-per-cpu=5G #SBATCH --mail-type=FAIL # Users should only need to change the dataset_dir to run this script. # set the path to the dataset directory. This is the parent to the BIDS-formatted nifti directory. dataset_dir = $USER_DATA /D01 # set the path to the BIDS-formatted nifti directory bidsdir = $dataset_dir /nifti/ # set the participant id from the participants.tsv file in the bidsdir pid = $( awk \"NR== $(( $SLURM_ARRAY_TASK_ID + 2 )) {print;exit}\" $bidsdir /participants.tsv | cut -f 1 ) # load the module module load rc/fmriprep/20.2.3 # run fmriprep fmriprep --work-dir $dataset_dir /workdir/ \\ --participant-label $pid \\ --output-spaces T1w \\ --fs-license-file $HOME /license.txt \\ --n-cpus 4 \\ --omp-nthreads 4 \\ --cifti-output 91k \\ $bidsdir \\ $bidsdir /derivatives \\ participant This script will replicate the fmriprep command for participants in the participants.tsv file. When submitting this job, include the --array=<min>-<max> option in the sbatch command representing the index of the participants you want to run. The index is 0-based. For example, if you want to run the first 10 participants in the file, use --array=0-9 , whereas if you want to run the 7th and 10th participant only, use --array=6,9 . This script can be placed in and run from a code folder placed under the main dataset directory to maintain BIDS compliance.","title":"Example fmriprep Scripts"},{"location":"analysis/fmriprep/fmriprep-scripts/#example-fmriprep-scripts","text":"","title":"Example fmriprep Scripts"},{"location":"analysis/fmriprep/fmriprep-scripts/#example-single-subject-job-script","text":"This example script was written to process a single subject P01 from BIDS-formatted dataset D01 stored in $USER_DATA . #!/bin/bash # #SBATCH --job-name=P01-fmriprep #SBATCH --output=$USER_DATA/D01/jobs/out/P01-fmriprep-out.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --partition=medium #SBATCH --time=50:00:00 #SBATCH --mem-per-cpu=5G #SBATCH --mail-type=FAIL # Users should only need to change the dataset_dir and the participant below to run this script. # set the path to the dataset directory. This is the parent to the BIDS-formatted nifti directory. dataset_dir = $USER_DATA /D01 # set the name of the participant participant = P01 # load the module module load rc/fmriprep/20.2.3 # run fmriprep fmriprep --work-dir $dataset_dir /workdir/ \\ --participant-label $participant \\ --output-spaces T1w \\ --fs-license-file $HOME /license.txt \\ --n-cpus 4 \\ --omp-nthreads 4 \\ --cifti-output 91k \\ $dataset_dir /nifti/ \\ $dataset_dir /nifti/derivatives \\ participant The job requests 4 CPUs and 4 GBs of memory per CPU for 50 hours total on the medium partition. The working directory was placed directly underneath the dataset directory The output space of the BOLD images was set to native T1w space as opposed to a normalized template space. The copied FreeSurfer license file was placed in my home directory and referenced in the script. All outputs were requested to be in cifti-space (91k default) The bids_dir , output_dir , and analysis_level were listed in that order after the options. This script can be submitted to the scheduler using sbatch <script.sh> where script.sh is the full path of the script (or just the script name if the terminal working directory contains the script).","title":"Example Single-Subject Job Script"},{"location":"analysis/fmriprep/fmriprep-scripts/#example-array-job-script","text":"SLURM job arrays are scripts made to easily replicate a job to be performed across multiple inputs (i.e. multiple participants) while not taxing the job scheduler. Read more about SLURM job arrays at their documentation . This example script was written to process all subjects from the participants.tsv file in BIDS-formatted dataset D01 . #!/bin/bash # #SBATCH --job-name=fmriprep-%a #SBATCH --output=fmriprep-%A-%a.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --partition=medium #SBATCH --time=50:00:00 #SBATCH --mem-per-cpu=5G #SBATCH --mail-type=FAIL # Users should only need to change the dataset_dir to run this script. # set the path to the dataset directory. This is the parent to the BIDS-formatted nifti directory. dataset_dir = $USER_DATA /D01 # set the path to the BIDS-formatted nifti directory bidsdir = $dataset_dir /nifti/ # set the participant id from the participants.tsv file in the bidsdir pid = $( awk \"NR== $(( $SLURM_ARRAY_TASK_ID + 2 )) {print;exit}\" $bidsdir /participants.tsv | cut -f 1 ) # load the module module load rc/fmriprep/20.2.3 # run fmriprep fmriprep --work-dir $dataset_dir /workdir/ \\ --participant-label $pid \\ --output-spaces T1w \\ --fs-license-file $HOME /license.txt \\ --n-cpus 4 \\ --omp-nthreads 4 \\ --cifti-output 91k \\ $bidsdir \\ $bidsdir /derivatives \\ participant This script will replicate the fmriprep command for participants in the participants.tsv file. When submitting this job, include the --array=<min>-<max> option in the sbatch command representing the index of the participants you want to run. The index is 0-based. For example, if you want to run the first 10 participants in the file, use --array=0-9 , whereas if you want to run the 7th and 10th participant only, use --array=6,9 . This script can be placed in and run from a code folder placed under the main dataset directory to maintain BIDS compliance.","title":"Example Array Job Script"},{"location":"analysis/fmriprep/fmriprep-usage/","text":"Using fmriprep on Cheaha \u00b6 Full documentation on executing fmriprep can be found on its ReadTheDocs . Instructions here will cover some of the material from the main docs tailored to use on the Cheaha computing cluster at UAB. The easiest way to access fmriprep on Cheaha is through using the module for version 20.2.3 (the most recent as of September 2021) already installed on the cluster. It is assumed at this point that all your data is stored in a valid BIDS format . fmriprep can perform BIDS validation during runtime, or you can perform BIDS validation here . Note If you require an older version of fmriprep, it's suggested you download the version you need as a Singularity container. More information on use of fmriprep via Singularity can be found here . Singularity versions >= v2.5 are available as modules on Cheaha. Loading the Module \u00b6 Cheaha users can access a variety of installed software through modules. Loading the module to use in either an interactive session or in a batch job can be done using the following command: module load rc/fmriprep/20.2.3 From here, you have access to all commands available in the fmriprep toolbox, mainly the fmriprep command. Required Positional Arguments \u00b6 The basic form of the fmriprep command is: fmriprep [ options ] bids_dir output_dir analysis_level bids_dir: root folder of a valid BIDS dataset (sub-XXXXX folders are found the output path for the outcomes of preprocessing and visual reports) output_dir: the output path for the outcomes of preprocessing and visual reports. In a BIDS structure, this should be set to \\ /derivatives analysis_level: preprocessing stage to be run. 'participant' is the only available choice for fmriprep These are the only options that must be listed every time fmriprep is run. A multitude of optional argument, some of which are covered below, can define how fmriprep behaves in with finer control. All options are listed on the fmriprep usage notes . It is highly advised to familiarize yourself with all available options for the fmriprep command before use. Select Optional Arguments \u00b6 --work-dir: directory to place immediate outputs --participant-label: list of participant identifiers ('sub-' tag optional) --output-spaces: which standardized or native space to sample functional data onto. Options include standard MNI, native T1w, and many, many others. Note Standardized atlas choices are those in TemplateFlow. Please view the fmriprep documenation to use the output_spaces option correctly. FreeSurfer Options \u00b6 --fs-no-reconall: disable the recon-all portion of the pipeline --fs-license-file: path to an available FreeSurfer license file. See fs-license for details Performance Options \u00b6 --n-cpus: total number of cpus available for the job --mem: total amount of memory available for the job (in MB) --omp-nthreads: maximum number of threads per process Surface Preprocessing Options \u00b6 --cifti-output: output processed BOLD in CIFTI format. Choices are 91k or 170k Note Although the naming convention is different here, the 91k option corresponds to the fs_LR 32k grayordinate space from HCP. FreeSurfer License File \u00b6 Because FreeSurfer is a proprietary software package, it needs a license file to run. A license file for FreeSurfer is provided on Cheaha. Run the following command, replacing <destination> with the location you would like to copy the license file to in your chosen workspace. cp /share/apps/rc/software/FreeSurfer/7.1.1-centos7_x86_64/license.txt <destination> Use the --fs-license-file option followed by the path to your copied license.txt. file to use FreeSurfer during data preprocessing. Suggested Computational Resources \u00b6 While it is difficult to guess the exact correct amount of resources needed for any given preprocessing job, general guidelines have been given here . Briefly, 4 CPUs and 5 GBs per CPU (20 total GBs) can complete preprocessing (without FreeSurfer surface reconstruction) in approximately 2 hours. Including surface reconstruction will dramatically increase the amount of time required, but the resources required should be consistent. Note While increasing the amount of resources will decrease computation time, there is a limit, and no performance increase was seen past 16 CPUs. Recognize that requesting a large number of CPUs for each of multiple preprocessing jobs will increase the amount of time needed to allocate resources for that job to start, increasing total time from job submission to finish and functionally minimizing the gains of using a large amount of resources in the first place. Even though the main documentation claims processing without surface reconstruction can be performed in 2 hours, it is advised that extra time be requested in case a processing step takes longer than normal. 6-12 hours on the short partition when not performing recon-all, or 32-50 hours on the medium partition (depending on the total number of scans to process) when performing recon-all is suggested.","title":"Using fmriprep on Cheaha"},{"location":"analysis/fmriprep/fmriprep-usage/#using-fmriprep-on-cheaha","text":"Full documentation on executing fmriprep can be found on its ReadTheDocs . Instructions here will cover some of the material from the main docs tailored to use on the Cheaha computing cluster at UAB. The easiest way to access fmriprep on Cheaha is through using the module for version 20.2.3 (the most recent as of September 2021) already installed on the cluster. It is assumed at this point that all your data is stored in a valid BIDS format . fmriprep can perform BIDS validation during runtime, or you can perform BIDS validation here . Note If you require an older version of fmriprep, it's suggested you download the version you need as a Singularity container. More information on use of fmriprep via Singularity can be found here . Singularity versions >= v2.5 are available as modules on Cheaha.","title":"Using fmriprep on Cheaha"},{"location":"analysis/fmriprep/fmriprep-usage/#loading-the-module","text":"Cheaha users can access a variety of installed software through modules. Loading the module to use in either an interactive session or in a batch job can be done using the following command: module load rc/fmriprep/20.2.3 From here, you have access to all commands available in the fmriprep toolbox, mainly the fmriprep command.","title":"Loading the Module"},{"location":"analysis/fmriprep/fmriprep-usage/#required-positional-arguments","text":"The basic form of the fmriprep command is: fmriprep [ options ] bids_dir output_dir analysis_level bids_dir: root folder of a valid BIDS dataset (sub-XXXXX folders are found the output path for the outcomes of preprocessing and visual reports) output_dir: the output path for the outcomes of preprocessing and visual reports. In a BIDS structure, this should be set to \\ /derivatives analysis_level: preprocessing stage to be run. 'participant' is the only available choice for fmriprep These are the only options that must be listed every time fmriprep is run. A multitude of optional argument, some of which are covered below, can define how fmriprep behaves in with finer control. All options are listed on the fmriprep usage notes . It is highly advised to familiarize yourself with all available options for the fmriprep command before use.","title":"Required Positional Arguments"},{"location":"analysis/fmriprep/fmriprep-usage/#select-optional-arguments","text":"--work-dir: directory to place immediate outputs --participant-label: list of participant identifiers ('sub-' tag optional) --output-spaces: which standardized or native space to sample functional data onto. Options include standard MNI, native T1w, and many, many others. Note Standardized atlas choices are those in TemplateFlow. Please view the fmriprep documenation to use the output_spaces option correctly.","title":"Select Optional Arguments"},{"location":"analysis/fmriprep/fmriprep-usage/#freesurfer-options","text":"--fs-no-reconall: disable the recon-all portion of the pipeline --fs-license-file: path to an available FreeSurfer license file. See fs-license for details","title":"FreeSurfer Options"},{"location":"analysis/fmriprep/fmriprep-usage/#performance-options","text":"--n-cpus: total number of cpus available for the job --mem: total amount of memory available for the job (in MB) --omp-nthreads: maximum number of threads per process","title":"Performance Options"},{"location":"analysis/fmriprep/fmriprep-usage/#surface-preprocessing-options","text":"--cifti-output: output processed BOLD in CIFTI format. Choices are 91k or 170k Note Although the naming convention is different here, the 91k option corresponds to the fs_LR 32k grayordinate space from HCP.","title":"Surface Preprocessing Options"},{"location":"analysis/fmriprep/fmriprep-usage/#freesurfer-license-file","text":"Because FreeSurfer is a proprietary software package, it needs a license file to run. A license file for FreeSurfer is provided on Cheaha. Run the following command, replacing <destination> with the location you would like to copy the license file to in your chosen workspace. cp /share/apps/rc/software/FreeSurfer/7.1.1-centos7_x86_64/license.txt <destination> Use the --fs-license-file option followed by the path to your copied license.txt. file to use FreeSurfer during data preprocessing.","title":"FreeSurfer License File"},{"location":"analysis/fmriprep/fmriprep-usage/#suggested-computational-resources","text":"While it is difficult to guess the exact correct amount of resources needed for any given preprocessing job, general guidelines have been given here . Briefly, 4 CPUs and 5 GBs per CPU (20 total GBs) can complete preprocessing (without FreeSurfer surface reconstruction) in approximately 2 hours. Including surface reconstruction will dramatically increase the amount of time required, but the resources required should be consistent. Note While increasing the amount of resources will decrease computation time, there is a limit, and no performance increase was seen past 16 CPUs. Recognize that requesting a large number of CPUs for each of multiple preprocessing jobs will increase the amount of time needed to allocate resources for that job to start, increasing total time from job submission to finish and functionally minimizing the gains of using a large amount of resources in the first place. Even though the main documentation claims processing without surface reconstruction can be performed in 2 hours, it is advised that extra time be requested in case a processing step takes longer than normal. 6-12 hours on the short partition when not performing recon-all, or 32-50 hours on the medium partition (depending on the total number of scans to process) when performing recon-all is suggested.","title":"Suggested Computational Resources"},{"location":"analysis/hcp_pipelines/","text":"HCP Pipelines \u00b6 The Human Connectome Project , as part of its goal for making MRI data acquisition and analysis more uniform across projects and sites, developed a series of preprocessing pipelines for MRI images. These pipelines take advantage of the advanced image quality of HCP sequences and are available for multiple modalities including structural, functional, diffusion, and more. The HCP Pipelines are distributed as a collection of shell scripts that are able to be run on Cheaha at UAB with some changes. This documentation will give an overview of the major features of the pipelines as well as some example scripts. What is Included in the Pipelines \u00b6 The HCP Pipelines are a collection of different pipelines for minimal preprocessing of structural, functional, and diffusion MRI images. In this instance, minimal preprocessing refers to only performing steps deemed absolutely critical to convert raw data to a form ready for analysis. If further preprocessing is desired, the outputs of the HCP pipelines can be used as inputs. A complete definition of what is included in minimal preprocessing can be found in the Glasser et al. 2013 paper describing each pipeline. Important It is highly recommended to read the Glasser paper linked above to become familiar with the steps the HCP Pipelines include for preprocessing. The instructions included here will provide some information but will not be near exhaustive. Data Quality for Pipelines \u00b6 HCP Pipelines were developed to be used on high resolution MRI data acquired through, at the time, state-of-the-art scanning sequences. As such, these pipelines do not provide improved performance over standard pipelines for all datasets. To see what kind of MRI data you need in order to effectively use these pipelines, please visit their FAQ . Important These pipelines will not run without field map data for distortion correction, including the structural pipelines. Please be sure to acquire these field maps during your session. Installation \u00b6 The pipelines are currently only distributed as shell scripts from the HCP github repository . You can either download the repository as a ZIP file using the green Code dropdown menu, or you can clone the repository onto Cheaha directly (recommended). To clone the repository, request an HPC Desktop session using Cheaha's Open OnDemand portal , open a terminal once the job has started, and navigate to the directory you would like to store the scripts in. Run the following command: git clone https://github.com/Washington-University/HCPpipelines.git Raw Data Setup \u00b6 Unlike fmriprep, another minimal preprocessing pipeline, the HCP Pipelines are not BIDS apps, so the input data do not need to be in BIDS format. Nonetheless, it is highly recommended that you convert data to BIDS format before using the pipelines as this converts your raw data to a standard and predictable organization minimizing time spent debugging why the pipeline may have failed for individual participants. To learn more about conversion to BIDS format, please read our documentation on the subject . If you choose not to convert to BIDS beforehand, make sure your raw data has a consistent organization and naming structure across scan types and participants.","title":"Introduction"},{"location":"analysis/hcp_pipelines/#hcp-pipelines","text":"The Human Connectome Project , as part of its goal for making MRI data acquisition and analysis more uniform across projects and sites, developed a series of preprocessing pipelines for MRI images. These pipelines take advantage of the advanced image quality of HCP sequences and are available for multiple modalities including structural, functional, diffusion, and more. The HCP Pipelines are distributed as a collection of shell scripts that are able to be run on Cheaha at UAB with some changes. This documentation will give an overview of the major features of the pipelines as well as some example scripts.","title":"HCP Pipelines"},{"location":"analysis/hcp_pipelines/#what-is-included-in-the-pipelines","text":"The HCP Pipelines are a collection of different pipelines for minimal preprocessing of structural, functional, and diffusion MRI images. In this instance, minimal preprocessing refers to only performing steps deemed absolutely critical to convert raw data to a form ready for analysis. If further preprocessing is desired, the outputs of the HCP pipelines can be used as inputs. A complete definition of what is included in minimal preprocessing can be found in the Glasser et al. 2013 paper describing each pipeline. Important It is highly recommended to read the Glasser paper linked above to become familiar with the steps the HCP Pipelines include for preprocessing. The instructions included here will provide some information but will not be near exhaustive.","title":"What is Included in the Pipelines"},{"location":"analysis/hcp_pipelines/#data-quality-for-pipelines","text":"HCP Pipelines were developed to be used on high resolution MRI data acquired through, at the time, state-of-the-art scanning sequences. As such, these pipelines do not provide improved performance over standard pipelines for all datasets. To see what kind of MRI data you need in order to effectively use these pipelines, please visit their FAQ . Important These pipelines will not run without field map data for distortion correction, including the structural pipelines. Please be sure to acquire these field maps during your session.","title":"Data Quality for Pipelines"},{"location":"analysis/hcp_pipelines/#installation","text":"The pipelines are currently only distributed as shell scripts from the HCP github repository . You can either download the repository as a ZIP file using the green Code dropdown menu, or you can clone the repository onto Cheaha directly (recommended). To clone the repository, request an HPC Desktop session using Cheaha's Open OnDemand portal , open a terminal once the job has started, and navigate to the directory you would like to store the scripts in. Run the following command: git clone https://github.com/Washington-University/HCPpipelines.git","title":"Installation"},{"location":"analysis/hcp_pipelines/#raw-data-setup","text":"Unlike fmriprep, another minimal preprocessing pipeline, the HCP Pipelines are not BIDS apps, so the input data do not need to be in BIDS format. Nonetheless, it is highly recommended that you convert data to BIDS format before using the pipelines as this converts your raw data to a standard and predictable organization minimizing time spent debugging why the pipeline may have failed for individual participants. To learn more about conversion to BIDS format, please read our documentation on the subject . If you choose not to convert to BIDS beforehand, make sure your raw data has a consistent organization and naming structure across scan types and participants.","title":"Raw Data Setup"},{"location":"analysis/hcp_pipelines/structural_pipeline/","text":"Structural Pipeline \u00b6 The structural pipeline performs preprocessing for T1w and T2w images and is made up of 3 scripts: the PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines which must be run in that specific order. As the names suggest, the structural pipeline is built around FreeSurfer's surface reconstruction. Some minor distortion correction is performed prior to surface reconstruction as well as conversion of surfaces from FreeSurfer space to fs_LR (the standard HCP) space after reconstruction. 1 Setup \u00b6 Modules \u00b6 First, some external modules are necessary for running these pipelines. The HCP Pipelines take advantage of both FreeSurfer and FSL, but these software packages are not included in the pipeline files. Therefore, you will need to load both of these prior to running the scripts Note The HCP FAQ currently says that the pipelines do not work with FreeSurfer version 7. You will need to use version 6 that is installed on Cheaha. The following modules have been tested with the structural pipeline, and the commands loading them can be included at the top of your script before running the pipeline: module load FreeSurfer/6.0.0-centos6_x86_64 module load FSL/6.0.3 source ${ FSLDIR } /etc/fslconf/fsl.sh Anaconda \u00b6 While testing the PreFreeSurfer pipeline, an issue was encountered where the python library numpy was required but not found on the default path. To resolve this issue, create an Anaconda environment with numpy installed. This can be done with the following commands: module load Anaconda3/2020.11 conda create -n preFS numpy From here, whenever you run the pipeline, you should load the Anaconda module and then activate the environment using conda activate preFS PreFreeSurfer Pipeline \u00b6 The shell script for running the PreFS pipeline can be found in the PreFreeSurfer directory in your HCP Pipelines directory. The script is already executable by default, so no permissions should need to be changed in order to run it. Some environment variables will need to be set up prior to executing the pipeline. This pipeline performs ACPC alignment, readout distortion correction, cross-model registration, and bias field correction (see Figure 9 in Glasser et al. 2013 ) of T1w and T2w images. The outputs of these steps are used for surface reconstruction in the FreeSurfer pipeline. PreFreeSurfer Environment Variables \u00b6 For all environment variables, set them using the following format: export <env_var> = <value> HCPPIPEDIR \u00b6 HCPPIPEDIR sets the main directory for where you have stored the pipelines. give the full path to the main directory, not just the PreFS directory. An example would look like: export HCPPIPEDIR = /home/mdefende/Scripts/HCPpipelines HCPPIPEDIR_Global \u00b6 This sets the path to the global scripts used across pipelines. If you set the HCPPIPEDIR variable first, you can just use: export HCPPIPEDIR_Global = ${ HCPPIPEDIR } /global/scripts HCPPIPEDIR_Templates \u00b6 This sets the path to the average templates used for converting data to specific spaces. This is also contained in the global directory. Just set it to: export HCPPIPEDIR_Global = ${ HCPPIPEDIR } /global/templates CARET7DIR \u00b6 In addition to the HCP Pipeline directory, another set of scripts is needed to run the pipeline, Caret7. This directory is included with the Connectome Workbench . You can either download the CentOS Linux distribution from the linked site and place it in your Cheaha space, or you can direct this variable to one of the installed Workbench modules on Cheaha. The path should end with the bin_rh_linux64 directory. # Link directly to the module export CARET7DIR = /share/apps/rc/software/ConnectomeWorkbench/1.5.0-rh_linux64/bin_rh_linux64 # OR download the distribution and link to it directly in your space export CARET7DIR = /home/mdefende/Scripts/workbench/bin_rh_linux64 Only one of the above lines is necessary. In the long run, it may be better to download your own copy of the Workbench and keep it as software may be removed from the cluster modules over a long period of time. SPIN_ECHO_METHOD_OPT \u00b6 This option sets the method for distortion correction. The default is using the FSL function topup. We can also set the method here, using the default method. export SPIN_ECHO_METHOD_OPT = \"TOPUP\" PreFreeSurfer Inputs \u00b6 There are a number of options that can/should be included when running the pipeline. In order to see all of the potential options, open a terminal, set your environment variables, navigate to the PreFreeSurfer directory. You can use the following command to list all of the potential options for the script: ./PreFreeSurfer.sh --help The PreFS pipeline has a large number of inputs that go along with it. For testing, we tried to be as verbose as possible, so some options may or may not be necessary. Here is a list: Note Some options use either the {x,y,z} triad or the {i,j,k} triad to denote axes in 3D space. {x,y,z} is FSL nomenclature while {i,j,k} is BIDS nomenclature. When testing with BIDS converted data, {i,j,k} gave reasonable outputs. {x,y,z} and non-BIDS data were not tested, so use at your own risk. Main Data: --path : the path to the main output directory. The full output path will be path/subject --subject : the name of the subject being processed. The full output path will be path/subject --t1 : the path to the input T1w nifti --t2 : the path to the input T2w nifti --t1samplespacing : sample spacing for the T1w scan in seconds. (see note under Spin Echo Field Maps) --t2samplespacing : sample spacing for the T2w scan in seconds. --unwarpdir : readout direction of the T1w and T2w images according to the voxel axes. One of {x,y,z,i,j,k,x-,y-,z-,i-,j-, or k-} . The - indicates the negative direction on the specified axis. When testing with T1 and T2 data from the HCP sequences, k gave reasonable outputs. Spin Echo Field Maps: --SEPhaseNeg : path to the spin echo field map in the negative phase-encoding direction (AP for data collected on the Anterior-Posterior axis) --SEPhasePos : path to the spin echo field map in the positive phase-encoding direction (PA for data collected on the Anterior-Posterior axis) --seechospacing : effective echo spacing for the spin echo field maps in seconds. --seunwarpdir : phase enconding direction according to the voxel axes for the spin echo field map. Can be either {x,y} , {i,j} , or NONE. {i,j} was used when testing data collected using HCP sequences and gave reasonable outputs. Note The sample spacing values for the T1 and T2 as well as the echo spacing value for the field maps can be found on a detailed scan export. Ask Elizabeth or Eleanor about how to export this from the scanner if your lab does not have one already. Template Options: These options define the standard atlases used for conversion from native to normalized space. The templates can be found the $HCPPIPEDIR_Templates directory you set previously. Multiple MNI templates at various resolutions are provided. --t1template : the T1 template. Can be any resolution. --t1templatebrain : the skull-stripped brain of the template named above. This is included in the template directory --templatemask : the brain mask for the chosen T1 template --t1template2mm : the 2mm MNI template --template2mmmask : brain mask for the 2mm T1 MNI template --t2template : the chosen T2 template. --t2templatebrain : skull stripped brain of the T2 template --t2template2mm : the 2mm T2 template Other Options: --avgrdcmethod : set to ${SPIN_ECHO_METHOD_OPT} --topupconfig : path to the topup configuration file. Can be set to ${HCPPIPEDIR}/global/config/b02b0.cnf --fnirtconfig : Config file for the 2mm template used during FNIRT. Can be set to ${HCPPIPEDIR}/global/config/T1_2_MNI152_2mm.cnf PreFreeSurfer Outputs \u00b6 The outputs for the PreFreeSurfer pipeline are divided into 3 directories: MNINonLinear , T1w , and T2w . The files with acpc_dc_restore in the name are the final outputs. Both T1w_acpc_dc_restore and T2w_acpc_dc_restore images are in the T1w directory and should be used as inputs to the FreeSurfer pipeline. FreeSurfer Pipeline \u00b6 The main shell script for running the FreeSurfer pipeline can be found in the FreeSurfer directory in your HCP pipelines. The script is already executable by default, so no permissions should need to be changed in order to run it. Some environment variables will need to be set up prior to executing the pipeline. This script is basically set up to only run the FreeSurfer recon-all command with minor adjustements to take advantage of sub-1mm^3^ voxel sizes, but this step comprises the bulk of the compute time for the structural pipeline. FreeSurfer Environment Variables \u00b6 The environment variables are much simpler for the FreeSurfer pipeline, only the HCPPIPEDIR and CARET7DIR variables are necessary. Set each of these in the same way you set them in the PreFreeSurfer environment section . tkregister \u00b6 One alteration will need to be made to the FreeSurferPipeline.sh script before it can be run. It uses an outdated command called tkregister for the last section of the pipeline. This command is packaged with the Freesurfer module, and version 6.0.0 has updated the command name. tkregister no longer exists and will throw an error at the end of the pipeline. In order to fix this, change the following sections of code (lines 77-79 in HCP pipelines version 4.3.0): 77 78 79 80 # Original log_Msg \"Showing tkregister version\" which tkregister tkregister -version should be changed to: 77 78 79 80 # New log_Msg \"Showing tkregister version\" which tkregister2_cmdl tkregister2_cmdl -version Additionally, line 781 should be changed from: 781 tkregister_cmd = \"tkregister\" to 781 tkregister_cmd = \"tkregister2_cmdl\" The same change should be made to line 814 814 tkregister_cmd = \"tkregister2_cmdl\" After these changes are made, the pipeline should run correctly. FreeSurfer Inputs \u00b6 The FreeSurfer pipeline only has a few necessary arguments to add to the function call and a couple of extra you can add that change the performance of FreeSurfer itself. In order to see all of the potential options, open a terminal, set your environment variables, navigate to the FreeSurfer directory. You can use the following command to list all of the potential options for the script: ./FreeSurfer.sh --help Output Options \u00b6 --subject-dir : sets the path to the subjects' directory that stores the FreeSurfer outputs. --subject : setting the individual subject's directory name. Should ideally be the same as the name of the subject used during PreFreeSurfer. Note It is highly recommended that the --subject-dir is separate from the PreFreeSurfer outputs. FreeSurfer uses a SUBJECTS_DIR environment variable that assumes that all Freesurfer outputs for all subjects in a dataset are contained in that immediate directory. This is not possible if the FreeSurfer outputs are kept in the PreFreeSurfer output directory. Input Files \u00b6 --t1 : the full path to the T1w image from the PreFreeSurfer outputs. The input T1 should be T1w_acpc_dc_restore.nii.gz --t1brain : the full path to the brain-extracted T1w image from the PreFreeSurfer outputs. Should be T1w_acpc_dc_restore_brain.nii.gz --t2 : the full path to the T2w image from the PreFreeSurfer outputs. The input T2 should be T2w_acpc_dc_restore.nii.gz . This is found in the T1w directory Optional Arguments \u00b6 --recon-seed : sets the random seed for recon-all surface segmentation --flair : tells recon-all to run with the -FLAIR option instead of the normal -T2 option. The FLAIR image should still be input using the --t2 option above. --existing-subject : says that the recon has been at least partially performed already. This option should be paired with the --extra-reconall-args option to say which recon stage recon-all should start from. --extra-reconall-args : extra arguments to pass to recon-all. See FreeSurferPipeline.sh's help output for details on how to use this option FreeSurfer Outputs \u00b6 FreeSurfer outputs will be stored in the subjects directory set in the pipeline. This directory will contain a folder for each subject ran. These folders contain all of the normal FreeSurfer outputs. More information on this can be found on the FreeSurfer website . PostFreeSurfer Pipeline \u00b6 The final part of the structural pipeline, the PostFreeSurfer pipeline, converts FreeSurfer outputs to native and standard fs_LR meshes of brainordinates and generates the final brain mask, the cortical ribbon volume, and the cortical myelin maps. At the end of the pipeline, all of the major surfaces and volumes are in a standardized CIFTI space viewable on the fs_LR average brain using ConnectomeWorkbench's wb_view . To create some of the files viewable in wb_view , a ConnectomeWorkbench module will need to be loaded in your script. This can be seen in the example scripts below. PostFreeSurfer Environment Variables \u00b6 The HCPPIPEDIR , CARET7DIR , and HCPPIPEDIR_Templates environment variables used in the PreFreeSurfer pipeline are used here again. Be sure to set them to the same locations. In addition, there are a few new variables that need to be set. HCPPIPEDIR_Config \u00b6 This sets the path to some color tables necessary for converting FreeSurfer annotations. If you set the HCPPIPEDIR variable first, you can just use: export HCPPIPEDIR_config = ${ HCPPIPEDIR } /global/config MSMBINDIR \u00b6 This sets the path to the binaries directory containing the msm command. This is a special folder that is not contained within the main HCP pipelines distribution. Please download the MSM_HOCR zip file, create a containing folder in your main HCP Pipelines directory, and extract the zip file into that containing folder. Ideally it would look something like .../HCPpipelines/MSM_HOCR/extracted files here... . This variable will then point the to MSM_HOCR folder. Note This zip file was created from the MSM_HOCR github repo . Use straight from the repo requires some compilation and troubleshooting and is not adequately explained in the instructions. Until a new version is released and required for a new version of the overall pipelines, use the zip file linked above to save time. MSMCONFIGDIR \u00b6 This sets the path to the configuration directory for MSM. This directory is included with the main distribution of the pipelines and is located at ${HCPPIPEDIR}/MSMConfig . PostFreeSurfer Inputs \u00b6 Required Arguments : --study-folder : the path to the folder containing all subjects' Freesurfer outputs --subject : the subject ID --surfatlasdir : path to the standardized surface templates. Set to ${HCPPIPEDIR_templates}/standard_mesh_atlases --grayordinatesres : resolution of grayordinates to use, usually 2 --grayordinatesdir : set to ${HCPPIPEDIR_templates}/<num>_Greyordinates . The value for <num> should be linked --grayordinatesres . For example, if --grayordinatesres was set to 2, set <num> here to 91282 . --hiresmesh : set to 164 --loresmesh : set to 32 --subcortgraylabels : path to the lookup table containing the subcortical label names and color values. Set to ${HCPPIPEDIR_config}/FreeSurferSubcorticalLabelTableLut.txt --freesurferlabels : path to the lookup table containing all of the ROI names and color values. Set to ${HCPPIPEDIR_config}/FreeSurferAllLut.txt --refmyelinmaps : path to the hi-res group reference myelin maps. Set this to ${HCPPIPEDIR_templates}/standard_mesh_atlases/Conte69.MyelinMap_BC.164k_fs_LR.dscalar.nii . Optional Arguments : For the most part, the default values for the optional arguments will suffice. Do not change these unless you know what you're doing. --mcsigma : myelin map bias correction sigma, default is 14.14213562373095048801 --regname : surface registration to use, default is MSMSulc --inflatescale : surface inflation scaling factor, default is 1 --processing-mode : either HCPStyleData (default) or LegacyStyleData. This can disable some of the preprocessing steps if the acquired data do not meet HCP acquisition guidelines. --structural-qc : set to yes (default) , no , or only . Whether to run structural qc or not. PostFreeSurfer Outputs \u00b6 Outputs will be somewhat scattered between the subject's T1w and MNINonLinear directories. Basic surface information such as thickness and curvature files are converted to GIFTI format T1w Directory \u00b6 The main additions to this directory are the following: fsaverage_LR32k : directory containing the fsaverage surfaces in GIFTI transformed to the fs_LR32k mesh Native : native space participant surfaces in GIFTI format aparc+aseg volumes : FreeSurfer's general parcellation and segmentation volume transformed to native T1w_acpc space. Available in native resolution and 1mm isotropic brainmask and cortical ribbon files MNINonLinear \u00b6 Most of the PostFS output surfaces from the T1w directory seem to have been copied to the MNINonLinear directory as well. All major surfaces and volumes either extracted or derived from Freesurfer outputs have been transferred to the fs_LR 164k mesh and are stored in the top level of the MNINonLinear directory. This includes things like the smoothed and unsmoothed myelin maps. fsaverage_LR32k and Native contain most of the 164k mesh surfaces on the 32k and native meshes, respectively. The large number of generated surfaces may seem overwhelming, so for visualization, it is suggested to begin using the auto-generated .scene and .spec files. In the main MNINonLinear directory, there will be a file named <sub>.164k_fs_LR.wb.spec . This file can be opened directly using wb_view , part of the Connectome Workbench toolbox . It will load a number of surfaces and volumes for you to view the data for your subject. Additionally, there is a StructuralQC folder with a file called <sub>.structuralQC.wb_scene you can use to easily load volumes and surfaces for visual inspection. To see the scene file when trying open files, you will need to change the file type filter. Warning Currently, Cheaha does not have the graphic capabilities to use wb_view in a stable way. Please use your local machine for viewing data. Additionally, the scene and spec files do not contain data themselves as they only point to the volumes and surfaces. The entire participant's output folder including MNINonLinear, T1w, and T2w will need to be downloaded to be able to use these scene and spec files. Output Surface Glossary \u00b6 All of the listed files will be from the 164k mesh, the standard high res output in the MNINonLinear directory. There are a number of different file types (i.e. metric scalar, dtseries, etc.). For more information about the Workbench file types, please read see https://balsa.wustl.edu/about/fileTypes . Given names here will omit the 164k_fs_LR tag for brevity CIFTI Files \u00b6 aparc.dlabel.nii : standard FreeSurfer parcellation from the Desikan-Killiany atlas. Contains cortical and subcortical ROIs aparc.a2009s.dlabel.nii : standard FreeSurfer parcellation from the Destrieux atlas. Contains cortical and subcortical ROIs ArealDistortion.dscalar.nii : measure of change of area at each vertex between native and fs_LR spheres after conversion using either MSMSulc or FreeSurfer. See more under the -caret5-method option on wb_command's help page corrThickness.dscalar.nii : cortical thickness with effects of curvature regressed out. See the HCP Users Archive for more info. curvature.dscalar.nii : curvature EdgeDistortion.dscalar.nii : Instead of taking the ratio of areas, it is instead a scaled log of average edge lengths connected to each vertex. See more under the -edge-method option on wb_command's help page MyelinMap.dscalar.nii : estimated myelin fraction measured as the ratio of the T1w image to the T2w image MyelinMap_BC.dscalar.nii : myelin values after bias correction SmoothedMyelinMap.dscalar.nii : myelin values after smoothing (FWHM = 5 according to CreateMyelinMaps.sh in PostFreeSurfer) SmoothedMyelinMap_BC.dscalar.nii : myelin values after smoothing and bias correction StrainJ.dscalar.nii StrainR.dscalar.nii sulc.dscalar.nii : how deep in a sulcus a vertex is. Measured relative to a midsurface, sulcal vertices are generally positive and gyral vertices are generally negative. thickness.dscalar.nii : raw thickness GIFTI Data Files \u00b6 Some of the label and shape files here are repeated from the CIFTI files, but only have data from either the left or right cortex with no subcortical data. Left and right hemispheres will be designated in the name of the surface file as L or R . aparc.label.gii aparc.a2009s.label.gii ArealDistortion.shape.gii atlasroi.shape.gii : cortical area that is considered outside the medial wall for the standard grayordinate spaces. corrThickness.shape.gii curvature.shape.gii EdgeDistortion.shape.gii MyelinMap.func.gii MyelinMap_BC.func.gii RefMyelinMap.func.gii : group-average reference myelin map refsulc.shape.gii : template files for MSMSulc registration to fs_LR SmoothedMyelinMap.func.gii : similar to above, except uses a 4 mm FWHM smoothing kernel after the MyelinMap was converted to GIFTI. The data do not come immediately from the CIFTI file SmoothedMyelinMap_BC.func.gii : similar to above, except uses a 4 mm FWHM smoothing kernel after the MyelinMap_BC was converted to GIFTI. The data do not come immediately from the CIFTI file StrainJ.shape.gii StrainR.shape.gii sulc.shape.gii thickness.shape.gii GIFTI Surface Files \u00b6 The files listed here contain information about the actual 3D models of the surfaces. These are the file that the GIFTI data files are plotted on top of. flat.surf.gii inflated.surf.gii : semi-inflated surface make sulcal vertices more visible midthickness.surf.gii : artificial surface designated as halfway between the white matter surface and the pial surface pial.surf.gii sphere.surf.gii very_inflated.surf.gii : maximally inflated surface white.surf.gii Example Scripts \u00b6 Both the single subject script and the array script were tested using data acquired with the HCP sequences and had been converted to BIDS format prior to preprocessing. The array script in particular uses the list of subjects output during BIDS conversion as a list of inputs for the array job. If your data are not BIDS formatted, this method of getting the subject ID and setting the paths to the input data will need to be amended. PreFreeSurfer: Single Subject Array Job FreeSurfer: Single Subject Array Job PostFreeSurfer: Single Subject Array Job For researchers new to running array jobs, please read over the documentation for array jobs at the Cheaha documentation . Thanks to Tori King and Dr. Nina Kraguljac for their contributions towards debugging and running the structural pipeline on Cheaha. \u21a9","title":"Structural Pipeline"},{"location":"analysis/hcp_pipelines/structural_pipeline/#structural-pipeline","text":"The structural pipeline performs preprocessing for T1w and T2w images and is made up of 3 scripts: the PreFreeSurfer, FreeSurfer, and PostFreeSurfer pipelines which must be run in that specific order. As the names suggest, the structural pipeline is built around FreeSurfer's surface reconstruction. Some minor distortion correction is performed prior to surface reconstruction as well as conversion of surfaces from FreeSurfer space to fs_LR (the standard HCP) space after reconstruction. 1","title":"Structural Pipeline"},{"location":"analysis/hcp_pipelines/structural_pipeline/#setup","text":"","title":"Setup"},{"location":"analysis/hcp_pipelines/structural_pipeline/#modules","text":"First, some external modules are necessary for running these pipelines. The HCP Pipelines take advantage of both FreeSurfer and FSL, but these software packages are not included in the pipeline files. Therefore, you will need to load both of these prior to running the scripts Note The HCP FAQ currently says that the pipelines do not work with FreeSurfer version 7. You will need to use version 6 that is installed on Cheaha. The following modules have been tested with the structural pipeline, and the commands loading them can be included at the top of your script before running the pipeline: module load FreeSurfer/6.0.0-centos6_x86_64 module load FSL/6.0.3 source ${ FSLDIR } /etc/fslconf/fsl.sh","title":"Modules"},{"location":"analysis/hcp_pipelines/structural_pipeline/#prefreesurfer-pipeline","text":"The shell script for running the PreFS pipeline can be found in the PreFreeSurfer directory in your HCP Pipelines directory. The script is already executable by default, so no permissions should need to be changed in order to run it. Some environment variables will need to be set up prior to executing the pipeline. This pipeline performs ACPC alignment, readout distortion correction, cross-model registration, and bias field correction (see Figure 9 in Glasser et al. 2013 ) of T1w and T2w images. The outputs of these steps are used for surface reconstruction in the FreeSurfer pipeline.","title":"PreFreeSurfer Pipeline"},{"location":"analysis/hcp_pipelines/structural_pipeline/#prefreesurfer-environment-variables","text":"For all environment variables, set them using the following format: export <env_var> = <value>","title":"PreFreeSurfer Environment Variables"},{"location":"analysis/hcp_pipelines/structural_pipeline/#prefreesurfer-inputs","text":"There are a number of options that can/should be included when running the pipeline. In order to see all of the potential options, open a terminal, set your environment variables, navigate to the PreFreeSurfer directory. You can use the following command to list all of the potential options for the script: ./PreFreeSurfer.sh --help The PreFS pipeline has a large number of inputs that go along with it. For testing, we tried to be as verbose as possible, so some options may or may not be necessary. Here is a list: Note Some options use either the {x,y,z} triad or the {i,j,k} triad to denote axes in 3D space. {x,y,z} is FSL nomenclature while {i,j,k} is BIDS nomenclature. When testing with BIDS converted data, {i,j,k} gave reasonable outputs. {x,y,z} and non-BIDS data were not tested, so use at your own risk. Main Data: --path : the path to the main output directory. The full output path will be path/subject --subject : the name of the subject being processed. The full output path will be path/subject --t1 : the path to the input T1w nifti --t2 : the path to the input T2w nifti --t1samplespacing : sample spacing for the T1w scan in seconds. (see note under Spin Echo Field Maps) --t2samplespacing : sample spacing for the T2w scan in seconds. --unwarpdir : readout direction of the T1w and T2w images according to the voxel axes. One of {x,y,z,i,j,k,x-,y-,z-,i-,j-, or k-} . The - indicates the negative direction on the specified axis. When testing with T1 and T2 data from the HCP sequences, k gave reasonable outputs. Spin Echo Field Maps: --SEPhaseNeg : path to the spin echo field map in the negative phase-encoding direction (AP for data collected on the Anterior-Posterior axis) --SEPhasePos : path to the spin echo field map in the positive phase-encoding direction (PA for data collected on the Anterior-Posterior axis) --seechospacing : effective echo spacing for the spin echo field maps in seconds. --seunwarpdir : phase enconding direction according to the voxel axes for the spin echo field map. Can be either {x,y} , {i,j} , or NONE. {i,j} was used when testing data collected using HCP sequences and gave reasonable outputs. Note The sample spacing values for the T1 and T2 as well as the echo spacing value for the field maps can be found on a detailed scan export. Ask Elizabeth or Eleanor about how to export this from the scanner if your lab does not have one already. Template Options: These options define the standard atlases used for conversion from native to normalized space. The templates can be found the $HCPPIPEDIR_Templates directory you set previously. Multiple MNI templates at various resolutions are provided. --t1template : the T1 template. Can be any resolution. --t1templatebrain : the skull-stripped brain of the template named above. This is included in the template directory --templatemask : the brain mask for the chosen T1 template --t1template2mm : the 2mm MNI template --template2mmmask : brain mask for the 2mm T1 MNI template --t2template : the chosen T2 template. --t2templatebrain : skull stripped brain of the T2 template --t2template2mm : the 2mm T2 template Other Options: --avgrdcmethod : set to ${SPIN_ECHO_METHOD_OPT} --topupconfig : path to the topup configuration file. Can be set to ${HCPPIPEDIR}/global/config/b02b0.cnf --fnirtconfig : Config file for the 2mm template used during FNIRT. Can be set to ${HCPPIPEDIR}/global/config/T1_2_MNI152_2mm.cnf","title":"PreFreeSurfer Inputs"},{"location":"analysis/hcp_pipelines/structural_pipeline/#prefreesurfer-outputs","text":"The outputs for the PreFreeSurfer pipeline are divided into 3 directories: MNINonLinear , T1w , and T2w . The files with acpc_dc_restore in the name are the final outputs. Both T1w_acpc_dc_restore and T2w_acpc_dc_restore images are in the T1w directory and should be used as inputs to the FreeSurfer pipeline.","title":"PreFreeSurfer Outputs"},{"location":"analysis/hcp_pipelines/structural_pipeline/#freesurfer-pipeline","text":"The main shell script for running the FreeSurfer pipeline can be found in the FreeSurfer directory in your HCP pipelines. The script is already executable by default, so no permissions should need to be changed in order to run it. Some environment variables will need to be set up prior to executing the pipeline. This script is basically set up to only run the FreeSurfer recon-all command with minor adjustements to take advantage of sub-1mm^3^ voxel sizes, but this step comprises the bulk of the compute time for the structural pipeline.","title":"FreeSurfer Pipeline"},{"location":"analysis/hcp_pipelines/structural_pipeline/#freesurfer-environment-variables","text":"The environment variables are much simpler for the FreeSurfer pipeline, only the HCPPIPEDIR and CARET7DIR variables are necessary. Set each of these in the same way you set them in the PreFreeSurfer environment section .","title":"FreeSurfer Environment Variables"},{"location":"analysis/hcp_pipelines/structural_pipeline/#tkregister","text":"One alteration will need to be made to the FreeSurferPipeline.sh script before it can be run. It uses an outdated command called tkregister for the last section of the pipeline. This command is packaged with the Freesurfer module, and version 6.0.0 has updated the command name. tkregister no longer exists and will throw an error at the end of the pipeline. In order to fix this, change the following sections of code (lines 77-79 in HCP pipelines version 4.3.0): 77 78 79 80 # Original log_Msg \"Showing tkregister version\" which tkregister tkregister -version should be changed to: 77 78 79 80 # New log_Msg \"Showing tkregister version\" which tkregister2_cmdl tkregister2_cmdl -version Additionally, line 781 should be changed from: 781 tkregister_cmd = \"tkregister\" to 781 tkregister_cmd = \"tkregister2_cmdl\" The same change should be made to line 814 814 tkregister_cmd = \"tkregister2_cmdl\" After these changes are made, the pipeline should run correctly.","title":"tkregister"},{"location":"analysis/hcp_pipelines/structural_pipeline/#freesurfer-inputs","text":"The FreeSurfer pipeline only has a few necessary arguments to add to the function call and a couple of extra you can add that change the performance of FreeSurfer itself. In order to see all of the potential options, open a terminal, set your environment variables, navigate to the FreeSurfer directory. You can use the following command to list all of the potential options for the script: ./FreeSurfer.sh --help","title":"FreeSurfer Inputs"},{"location":"analysis/hcp_pipelines/structural_pipeline/#freesurfer-outputs","text":"FreeSurfer outputs will be stored in the subjects directory set in the pipeline. This directory will contain a folder for each subject ran. These folders contain all of the normal FreeSurfer outputs. More information on this can be found on the FreeSurfer website .","title":"FreeSurfer Outputs"},{"location":"analysis/hcp_pipelines/structural_pipeline/#postfreesurfer-pipeline","text":"The final part of the structural pipeline, the PostFreeSurfer pipeline, converts FreeSurfer outputs to native and standard fs_LR meshes of brainordinates and generates the final brain mask, the cortical ribbon volume, and the cortical myelin maps. At the end of the pipeline, all of the major surfaces and volumes are in a standardized CIFTI space viewable on the fs_LR average brain using ConnectomeWorkbench's wb_view . To create some of the files viewable in wb_view , a ConnectomeWorkbench module will need to be loaded in your script. This can be seen in the example scripts below.","title":"PostFreeSurfer Pipeline"},{"location":"analysis/hcp_pipelines/structural_pipeline/#postfreesurfer-environment-variables","text":"The HCPPIPEDIR , CARET7DIR , and HCPPIPEDIR_Templates environment variables used in the PreFreeSurfer pipeline are used here again. Be sure to set them to the same locations. In addition, there are a few new variables that need to be set.","title":"PostFreeSurfer Environment Variables"},{"location":"analysis/hcp_pipelines/structural_pipeline/#postfreesurfer-inputs","text":"Required Arguments : --study-folder : the path to the folder containing all subjects' Freesurfer outputs --subject : the subject ID --surfatlasdir : path to the standardized surface templates. Set to ${HCPPIPEDIR_templates}/standard_mesh_atlases --grayordinatesres : resolution of grayordinates to use, usually 2 --grayordinatesdir : set to ${HCPPIPEDIR_templates}/<num>_Greyordinates . The value for <num> should be linked --grayordinatesres . For example, if --grayordinatesres was set to 2, set <num> here to 91282 . --hiresmesh : set to 164 --loresmesh : set to 32 --subcortgraylabels : path to the lookup table containing the subcortical label names and color values. Set to ${HCPPIPEDIR_config}/FreeSurferSubcorticalLabelTableLut.txt --freesurferlabels : path to the lookup table containing all of the ROI names and color values. Set to ${HCPPIPEDIR_config}/FreeSurferAllLut.txt --refmyelinmaps : path to the hi-res group reference myelin maps. Set this to ${HCPPIPEDIR_templates}/standard_mesh_atlases/Conte69.MyelinMap_BC.164k_fs_LR.dscalar.nii . Optional Arguments : For the most part, the default values for the optional arguments will suffice. Do not change these unless you know what you're doing. --mcsigma : myelin map bias correction sigma, default is 14.14213562373095048801 --regname : surface registration to use, default is MSMSulc --inflatescale : surface inflation scaling factor, default is 1 --processing-mode : either HCPStyleData (default) or LegacyStyleData. This can disable some of the preprocessing steps if the acquired data do not meet HCP acquisition guidelines. --structural-qc : set to yes (default) , no , or only . Whether to run structural qc or not.","title":"PostFreeSurfer Inputs"},{"location":"analysis/hcp_pipelines/structural_pipeline/#postfreesurfer-outputs","text":"Outputs will be somewhat scattered between the subject's T1w and MNINonLinear directories. Basic surface information such as thickness and curvature files are converted to GIFTI format","title":"PostFreeSurfer Outputs"},{"location":"analysis/hcp_pipelines/structural_pipeline/#output-surface-glossary","text":"All of the listed files will be from the 164k mesh, the standard high res output in the MNINonLinear directory. There are a number of different file types (i.e. metric scalar, dtseries, etc.). For more information about the Workbench file types, please read see https://balsa.wustl.edu/about/fileTypes . Given names here will omit the 164k_fs_LR tag for brevity","title":"Output Surface Glossary"},{"location":"analysis/hcp_pipelines/structural_pipeline/#example-scripts","text":"Both the single subject script and the array script were tested using data acquired with the HCP sequences and had been converted to BIDS format prior to preprocessing. The array script in particular uses the list of subjects output during BIDS conversion as a list of inputs for the array job. If your data are not BIDS formatted, this method of getting the subject ID and setting the paths to the input data will need to be amended. PreFreeSurfer: Single Subject Array Job FreeSurfer: Single Subject Array Job PostFreeSurfer: Single Subject Array Job For researchers new to running array jobs, please read over the documentation for array jobs at the Cheaha documentation . Thanks to Tori King and Dr. Nina Kraguljac for their contributions towards debugging and running the structural pipeline on Cheaha. \u21a9","title":"Example Scripts"},{"location":"analysis/qsiprep/","text":"QSIprep \u00b6 QSIprep is a BIDS app that performs minimal preprocessing for diffusion-weighted MRI (dMRI) data. Preprocessing steps include head motion correction, susceptibility distortion correction, MP-PCA denoising, coregistration to T1w images, spatial normalization and tissue segmentation using tools from popular standalone packages such as MRTrix, FSL, DSIStudio, and ANTs. For a full breakdown of the preprocessing pipeline, please visit their docs .","title":"Introduction"},{"location":"analysis/qsiprep/#qsiprep","text":"QSIprep is a BIDS app that performs minimal preprocessing for diffusion-weighted MRI (dMRI) data. Preprocessing steps include head motion correction, susceptibility distortion correction, MP-PCA denoising, coregistration to T1w images, spatial normalization and tissue segmentation using tools from popular standalone packages such as MRTrix, FSL, DSIStudio, and ANTs. For a full breakdown of the preprocessing pipeline, please visit their docs .","title":"QSIprep"},{"location":"analysis/qsiprep/qsiprep_usage/","text":"Using QSIprep on Cheaha \u00b6 Full documentation on using QSIprep can be found on their docs . Instructions here will cover a selection of their documentation tailored for use on Cheaha. Installation \u00b6 The suggested way to use QSIprep on Cheaha is through a Singularity container. These containers have all software necessary to run qsiprep packaged together, so no environments or external software management is necessary. To install the Singularity container for QSIprep, open an interactive session on Cheaha and run the following commands: module load Singularity/3.5.2-GCC-5.4.0-2.26 singularity pull qsiprep-0.14.3.sif docker://pennbbl/qsiprep:0.14.3 The container download and building process will take some time but once complete will not need to be performed again unless you want a different version. Note The suggested version of QSIprep to install is version 0.14.3, one major version behind as of the writing of these docs. Version 0.15.X have issues with the packaged miniconda distribution that cause runtime errors. Some published issues on QSIprep's github page suggest waiting until the next major release (0.16.1) for resolutions to these issues. Usage \u00b6 The basic command structure for qsiprep is fairly simple: singularity run <path/to/sif> [ optional_args ] <bids_dir> <output_dir> <analysis_level> Required Positional Arguments \u00b6 bids_dir : root folder of a BIDS-sorted dataset (contains the sub-XXXX BIDS directories) output_dir : path to the qsiprep outputs, typically named derivatives in a BIDS structure analysis_level : currently only participant Additional Arguments \u00b6 A full description of the optional arguments can be found in the QSIprep documentation . Some select options are listed below, but is nowhere near an exhaustive list. There are a number of options that can dramatically change preprocessing steps, so please read through the linked documentation above to tailor your pipeline to how you want it. --participant_label : participant to perform qsiprep on. Omit the sub- tag from the label. While there are ways to specify multiple participants in a single QSIprep script, these will run serially, and perprocessing time will be long. For multiple participants, array scripts are suggested instead for parallel processing. --separate_all_dwis : Default behavior for qsiprep is to concatenate multiple DWI runs together and then perform preprocessing ( see here ). This option will keep all DWIs separate during and after preprocessing. output_resolution : isotropic voxel size that DWIs will be resampled to after preprocessing. BSpline interpolation is used for upsampling to smaller voxels than in the raw data. This is a required argument . --fs_license_file : path to the FreeSurfer license file. See our fmriprep docs for more information. This is a required argument . --work_dir : path to a working directory to store intermediate results. These files will be deleted after the script ends. Fieldmaps \u00b6 If you are using fieldmaps for distortion correction, remember to include the IntendedFor field in the fieldmap json sidecars naming the diffusion scans they are intended to correct. Outputs \u00b6 A detailed list of qsiprep outputs can be found in their documentation . Example Scripts \u00b6 Single Subject \u00b6 #!/bin/bash # #SBATCH --job-name=S01-qsiprep #SBATCH --output=qsiprep-S01-out.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --partition=amd-hdr100 #SBATCH --time=50:00:00 #SBATCH --mem-per-cpu=10G # Users should only need to change the bids_dir and the participant below to run this script. # set the path to the dataset directory. This is the parent to the BIDS-formatted nifti directory. bids_dir = $USER_DATA /D01/nifti # set the name of the participant participant = S01 # load the module module load Singularity/3.5.2-GCC-5.4.0-2.26 # change directory to where qsiprep image file is stored cd ~/Scripts/qsiprep # run qsiprep singularity run qsiprep-0.14.3.sif --participant_label $participant \\ --fs_license_file $HOME /license.txt \\ -v \\ --separate_all_dwis \\ --output_resolution 1 .2 \\ --skip_bids_validation \\ $bids_dir \\ $bids_dir /derivatives \\ participant Array Job \u00b6 The array job uses the participants.tsv file generated in the main BIDS directory similar to our fmriprep examples . Array indexes for sbatch are 0's based, i.e. 0 will correspond to the first participant in the tsv file. The array script has been written to account for this. #!/bin/bash # #SBATCH --job-name=qsiprep #SBATCH --output=qsiprep-%A-%a.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --partition=amd-hdr100 #SBATCH --time=50:00:00 #SBATCH --mem-per-cpu=10G # set the path to the BIDS-formatted nifti directory bids_dir = $USER_DATA /D01/nifti/ # set the participant id from the participants.tsv file in the bidsdir participant = $( awk \"NR== $(( $SLURM_ARRAY_TASK_ID + 2 )) {print;exit}\" $bids_dir /participants.tsv | cut -f 1 ) # load the module module load Singularity/3.5.2-GCC-5.4.0-2.26 # change directory to where qsiprep image file is stored cd ~/Scripts/qsiprep # run qsiprep singularity run qsiprep-0.14.3.sif --participant_label $participant \\ --fs_license_file $HOME /license.txt \\ -v \\ --separate_all_dwis \\ --output_resolution 1 .2 \\ --skip_bids_validation \\ $bids_dir \\ $bids_dir /derivatives \\ participant","title":"Using QSIprep on Cheaha"},{"location":"analysis/qsiprep/qsiprep_usage/#using-qsiprep-on-cheaha","text":"Full documentation on using QSIprep can be found on their docs . Instructions here will cover a selection of their documentation tailored for use on Cheaha.","title":"Using QSIprep on Cheaha"},{"location":"analysis/qsiprep/qsiprep_usage/#installation","text":"The suggested way to use QSIprep on Cheaha is through a Singularity container. These containers have all software necessary to run qsiprep packaged together, so no environments or external software management is necessary. To install the Singularity container for QSIprep, open an interactive session on Cheaha and run the following commands: module load Singularity/3.5.2-GCC-5.4.0-2.26 singularity pull qsiprep-0.14.3.sif docker://pennbbl/qsiprep:0.14.3 The container download and building process will take some time but once complete will not need to be performed again unless you want a different version. Note The suggested version of QSIprep to install is version 0.14.3, one major version behind as of the writing of these docs. Version 0.15.X have issues with the packaged miniconda distribution that cause runtime errors. Some published issues on QSIprep's github page suggest waiting until the next major release (0.16.1) for resolutions to these issues.","title":"Installation"},{"location":"analysis/qsiprep/qsiprep_usage/#usage","text":"The basic command structure for qsiprep is fairly simple: singularity run <path/to/sif> [ optional_args ] <bids_dir> <output_dir> <analysis_level>","title":"Usage"},{"location":"analysis/qsiprep/qsiprep_usage/#required-positional-arguments","text":"bids_dir : root folder of a BIDS-sorted dataset (contains the sub-XXXX BIDS directories) output_dir : path to the qsiprep outputs, typically named derivatives in a BIDS structure analysis_level : currently only participant","title":"Required Positional Arguments"},{"location":"analysis/qsiprep/qsiprep_usage/#additional-arguments","text":"A full description of the optional arguments can be found in the QSIprep documentation . Some select options are listed below, but is nowhere near an exhaustive list. There are a number of options that can dramatically change preprocessing steps, so please read through the linked documentation above to tailor your pipeline to how you want it. --participant_label : participant to perform qsiprep on. Omit the sub- tag from the label. While there are ways to specify multiple participants in a single QSIprep script, these will run serially, and perprocessing time will be long. For multiple participants, array scripts are suggested instead for parallel processing. --separate_all_dwis : Default behavior for qsiprep is to concatenate multiple DWI runs together and then perform preprocessing ( see here ). This option will keep all DWIs separate during and after preprocessing. output_resolution : isotropic voxel size that DWIs will be resampled to after preprocessing. BSpline interpolation is used for upsampling to smaller voxels than in the raw data. This is a required argument . --fs_license_file : path to the FreeSurfer license file. See our fmriprep docs for more information. This is a required argument . --work_dir : path to a working directory to store intermediate results. These files will be deleted after the script ends.","title":"Additional Arguments"},{"location":"analysis/qsiprep/qsiprep_usage/#fieldmaps","text":"If you are using fieldmaps for distortion correction, remember to include the IntendedFor field in the fieldmap json sidecars naming the diffusion scans they are intended to correct.","title":"Fieldmaps"},{"location":"analysis/qsiprep/qsiprep_usage/#outputs","text":"A detailed list of qsiprep outputs can be found in their documentation .","title":"Outputs"},{"location":"analysis/qsiprep/qsiprep_usage/#example-scripts","text":"","title":"Example Scripts"},{"location":"analysis/qsiprep/qsiprep_usage/#single-subject","text":"#!/bin/bash # #SBATCH --job-name=S01-qsiprep #SBATCH --output=qsiprep-S01-out.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --partition=amd-hdr100 #SBATCH --time=50:00:00 #SBATCH --mem-per-cpu=10G # Users should only need to change the bids_dir and the participant below to run this script. # set the path to the dataset directory. This is the parent to the BIDS-formatted nifti directory. bids_dir = $USER_DATA /D01/nifti # set the name of the participant participant = S01 # load the module module load Singularity/3.5.2-GCC-5.4.0-2.26 # change directory to where qsiprep image file is stored cd ~/Scripts/qsiprep # run qsiprep singularity run qsiprep-0.14.3.sif --participant_label $participant \\ --fs_license_file $HOME /license.txt \\ -v \\ --separate_all_dwis \\ --output_resolution 1 .2 \\ --skip_bids_validation \\ $bids_dir \\ $bids_dir /derivatives \\ participant","title":"Single Subject"},{"location":"analysis/qsiprep/qsiprep_usage/#array-job","text":"The array job uses the participants.tsv file generated in the main BIDS directory similar to our fmriprep examples . Array indexes for sbatch are 0's based, i.e. 0 will correspond to the first participant in the tsv file. The array script has been written to account for this. #!/bin/bash # #SBATCH --job-name=qsiprep #SBATCH --output=qsiprep-%A-%a.txt #SBATCH --ntasks=1 #SBATCH --cpus-per-task=4 #SBATCH --partition=amd-hdr100 #SBATCH --time=50:00:00 #SBATCH --mem-per-cpu=10G # set the path to the BIDS-formatted nifti directory bids_dir = $USER_DATA /D01/nifti/ # set the participant id from the participants.tsv file in the bidsdir participant = $( awk \"NR== $(( $SLURM_ARRAY_TASK_ID + 2 )) {print;exit}\" $bids_dir /participants.tsv | cut -f 1 ) # load the module module load Singularity/3.5.2-GCC-5.4.0-2.26 # change directory to where qsiprep image file is stored cd ~/Scripts/qsiprep # run qsiprep singularity run qsiprep-0.14.3.sif --participant_label $participant \\ --fs_license_file $HOME /license.txt \\ -v \\ --separate_all_dwis \\ --output_resolution 1 .2 \\ --skip_bids_validation \\ $bids_dir \\ $bids_dir /derivatives \\ participant","title":"Array Job"},{"location":"scanner/data_management/","text":"Data Management \u00b6 Transferring Scans to OSIRIX \u00b6 Scan data is stored on the scanner computer immediately after acquisition. All DICOMs (most if not all non-MRS data) can be easily transferred to the OSIRIX database stored in the Highlands Scanner Office and transferred to an external disk from the Mac. To transfer scans to OSIRIX, perform the following steps: Open the patient file browser Select the participant you would like to transfer Select Transfer >> Send To >> OSIRIX Once this is selected, the transfer will begin. Non-DICOM Data \u00b6 Scan Data \u00b6 Non-dicom scan data must be transferred directly from the scanner computer to an external hard drive. These external hard drives must either come directly from CINL or be approved by CINL before use. Do not use anapproved hard disks to retrieve data directly from the scanner computer . This can cause issues with the scanner impacting future scans. Important CINL drives may never leave Zone III of Highlands MRI or be used with any computers outside of the Osirix computer and the console computer. CINL approved drives are either those that CINL provides, or hardware encrypted (not software encrypted), or have a write protect switch. If you decide to purchase a drive that meets CINL\u2019s qualifications, please let CINL staff know and we will label your drive accordingly. Note that CINL approved drives must only be used for transferring CINL data. Physiological Data \u00b6 Physiological data not stored as DICOMS must be retrieved from the scanner computer. These data are not stored in the File Browser with the scans. If you do not know how to access the physiological data, please request assistance from Eleanor or Elizabeth. Stimulus and Task Data \u00b6 when presenting and recording data using the stimulus Mac or Windows machine, those can can be directly retrieved from those machines using an external disk or transferred to cloud storage when using the Mac. After transfer, please remove the created data files to prevent storage from becoming full. Transferring Scans to XNAT \u00b6 XNAT is an online storage location for DICOM MRI data. You can transfer data directly to XNAT from the scanner computer and is freely available for anyone at UAB. Please read more about XNAT and how to use it in the XNAT documentation . Scan Data Storage Protocol \u00b6 Scan data is directly stored on the scanner computer after acquisition, but this computer is not meant for long-term data storage. Scans will be removed every week or when the local scanner drive is full. After being removed from this computer, if you did not transfer the data or the transfer was unsuccessful, the data is unrecoverable. It is good practice to transfer data to at least two of XNAT, OSIRIX, or a local drive. Do not leave data transfer up to chance!","title":"Local Transfer and OSIRIX"},{"location":"scanner/data_management/#data-management","text":"","title":"Data Management"},{"location":"scanner/data_management/#transferring-scans-to-osirix","text":"Scan data is stored on the scanner computer immediately after acquisition. All DICOMs (most if not all non-MRS data) can be easily transferred to the OSIRIX database stored in the Highlands Scanner Office and transferred to an external disk from the Mac. To transfer scans to OSIRIX, perform the following steps: Open the patient file browser Select the participant you would like to transfer Select Transfer >> Send To >> OSIRIX Once this is selected, the transfer will begin.","title":"Transferring Scans to OSIRIX"},{"location":"scanner/data_management/#non-dicom-data","text":"","title":"Non-DICOM Data"},{"location":"scanner/data_management/#transferring-scans-to-xnat","text":"XNAT is an online storage location for DICOM MRI data. You can transfer data directly to XNAT from the scanner computer and is freely available for anyone at UAB. Please read more about XNAT and how to use it in the XNAT documentation .","title":"Transferring Scans to XNAT"},{"location":"scanner/data_management/#scan-data-storage-protocol","text":"Scan data is directly stored on the scanner computer after acquisition, but this computer is not meant for long-term data storage. Scans will be removed every week or when the local scanner drive is full. After being removed from this computer, if you did not transfer the data or the transfer was unsuccessful, the data is unrecoverable. It is good practice to transfer data to at least two of XNAT, OSIRIX, or a local drive. Do not leave data transfer up to chance!","title":"Scan Data Storage Protocol"},{"location":"scanner/getting_started/","text":"Getting Started \u00b6 This documentation will provide a brief overview of the steps required to get your MRI project up and running at the CINL Prisma scanner. Apply for P-Number \u00b6 A P-number is how your specific project will be identified in the CINL system. All billing for scans will be applied to the account for the associated project for the P-number given during scan scheduling. In order to get a P-number, please fill out the MRI Only (Pre-Clinical/Basic Science) Inquiry Form and the \u201cMRI Only (Pre-Clinical/Basic Science) Review/Quote Request\u201d at the bottom of the New CINL Study Forms page. Send both of these completed forms to cinl@uab.edu. Please read the onboarding documentation for more information. Training \u00b6 If you and your study personnel have not already done so, you must undergo at least CINL MRI Safety Training. Please schedule this with Eleanor Yourich (elewis1@uabmc.edu). Please read over the training protocols for more information. Implants \u00b6 Before a scan begins, any participant must be screened to be sure no unsafe risk factors are present for being in an MRI. For more information on risk factor and implant policies and procedures, please read the implant documentation . Key Card Access \u00b6 To obtain key card access to the Prisma MRI scanner area, message Ingia Gentry at CINL@uab.edu. Please provide the string of numbers at the bottom of the back side of the UAB ID badge(the string usually starts with a \"4*\" and ends with a \"-E\u201d). Calendars \u00b6 To gain access to the Google calendars used for scheduling, please send a request to Eleanor Yourich at elewis1@uabmc.edu. You will need to provide Eleanor your email address and it is easiest to use a gmail address (which will also integrate it into their already existing google calendar). Warning This is a Google calendar, so no PHI should ever be entered! See scheduling documentation for more details on how to properly format a scan time request. Research groups may not use the scanner unless a request is submitted for a given timeslot. Email Listserv \u00b6 It is required to be subscribed to the CINL listserv for scan rescheduling and cancellation announcements. To join the listserv, send an email to listserv@listserv.uab.edu with the email body as sub cinl-notice. Afterwards, you\u2019ll receive an email to confirm your email address. After confirming your email address, you would start receiving cancellation emails from others on the list as well as be able to send your own notifications.","title":"Getting Started"},{"location":"scanner/getting_started/#getting-started","text":"This documentation will provide a brief overview of the steps required to get your MRI project up and running at the CINL Prisma scanner.","title":"Getting Started"},{"location":"scanner/getting_started/#apply-for-p-number","text":"A P-number is how your specific project will be identified in the CINL system. All billing for scans will be applied to the account for the associated project for the P-number given during scan scheduling. In order to get a P-number, please fill out the MRI Only (Pre-Clinical/Basic Science) Inquiry Form and the \u201cMRI Only (Pre-Clinical/Basic Science) Review/Quote Request\u201d at the bottom of the New CINL Study Forms page. Send both of these completed forms to cinl@uab.edu. Please read the onboarding documentation for more information.","title":"Apply for P-Number"},{"location":"scanner/getting_started/#training","text":"If you and your study personnel have not already done so, you must undergo at least CINL MRI Safety Training. Please schedule this with Eleanor Yourich (elewis1@uabmc.edu). Please read over the training protocols for more information.","title":"Training"},{"location":"scanner/getting_started/#implants","text":"Before a scan begins, any participant must be screened to be sure no unsafe risk factors are present for being in an MRI. For more information on risk factor and implant policies and procedures, please read the implant documentation .","title":"Implants"},{"location":"scanner/getting_started/#key-card-access","text":"To obtain key card access to the Prisma MRI scanner area, message Ingia Gentry at CINL@uab.edu. Please provide the string of numbers at the bottom of the back side of the UAB ID badge(the string usually starts with a \"4*\" and ends with a \"-E\u201d).","title":"Key Card Access"},{"location":"scanner/getting_started/#calendars","text":"To gain access to the Google calendars used for scheduling, please send a request to Eleanor Yourich at elewis1@uabmc.edu. You will need to provide Eleanor your email address and it is easiest to use a gmail address (which will also integrate it into their already existing google calendar). Warning This is a Google calendar, so no PHI should ever be entered! See scheduling documentation for more details on how to properly format a scan time request. Research groups may not use the scanner unless a request is submitted for a given timeslot.","title":"Calendars"},{"location":"scanner/getting_started/#email-listserv","text":"It is required to be subscribed to the CINL listserv for scan rescheduling and cancellation announcements. To join the listserv, send an email to listserv@listserv.uab.edu with the email body as sub cinl-notice. Afterwards, you\u2019ll receive an email to confirm your email address. After confirming your email address, you would start receiving cancellation emails from others on the list as well as be able to send your own notifications.","title":"Email Listserv"},{"location":"scanner/implants/","text":"MRI Screening and Implants \u00b6 Participant Screening \u00b6 Before beginning a scan, a participant must be taken through the MRI Patient Screening Form . This screening form is mandatory each time a participant comes in for a scan regardless of if they have filled out the form previously. Any risk factors discovered during the screening process will need to be reported and approved before scanning. For any questions about risk factors during screening, please contact Elizabeth Ingram (ekingram@uabmc.edu). Implant Policies \u00b6 If a participant has an implant, please reach out to Elizabeth Ingram (ekingram@uabmc.edu) and upload documentation for the implant to Sharefile for her to review. Please read the Implant Guide and reach out to Elizabeth with any questions. Keep in mind that certain implants may need more time or research any others. You can always ask general questions through email, however, you may be prompted to use ShareFile for in depth exchange of implant specifics and documentation.","title":"Screening and Implants"},{"location":"scanner/implants/#mri-screening-and-implants","text":"","title":"MRI Screening and Implants"},{"location":"scanner/implants/#participant-screening","text":"Before beginning a scan, a participant must be taken through the MRI Patient Screening Form . This screening form is mandatory each time a participant comes in for a scan regardless of if they have filled out the form previously. Any risk factors discovered during the screening process will need to be reported and approved before scanning. For any questions about risk factors during screening, please contact Elizabeth Ingram (ekingram@uabmc.edu).","title":"Participant Screening"},{"location":"scanner/implants/#implant-policies","text":"If a participant has an implant, please reach out to Elizabeth Ingram (ekingram@uabmc.edu) and upload documentation for the implant to Sharefile for her to review. Please read the Implant Guide and reach out to Elizabeth with any questions. Keep in mind that certain implants may need more time or research any others. You can always ask general questions through email, however, you may be prompted to use ShareFile for in depth exchange of implant specifics and documentation.","title":"Implant Policies"},{"location":"scanner/onboarding/","text":"Onboarding for New Studies \u00b6 The first step in establishing a new study with CINL is to complete and submit our Inquiry and Quote Request forms. Both of these forms can be found either embedded or linked on the Research MRI Core site . MRI Only (Pre-Clinical/Basic Science) Inquiry Form: This is a short form for basic information. This form is embedded at the site linked above. \u201cMRI Only (Pre-Clinical/Basic Science) Review/Quote Request\u201d: This form will take more time to complete and submit. It includes a request for a PDF of the protocol, however an idea of the sequences and total scan length should suffice temporarily until a complete protocol is in place. Initially, a PI can review the form and submit it after the required fields are completed. Please email Eleanor at elewis1@uabmc.edu after you submit the forms. Feel free to reach out to us with questions. After Quote Request submission, a staff member will contact you about training, study logistics, billing, etc. Note A completed Quote Request Form is required to get a P-number, which is a how your study will be identified as well as confirm the current per hour scan rate. Please submit this form on RedCap and then notify CINL (cinl@uab.edu). Development Hours \u00b6 Each study receives up to 5 hours of development time for protocol setup and testing purposes. Follow our Calendar instructions (linked) for requesting this time keeping in mind to indicate the P-number along with PI name(s) and \u201cdevelopment\u201d when scheduling development time on the scan calendar. Once your study begins, CINL will not cover the cost of continued development time. If you believe you will need more than 5 hours of development time, or if you will require continued development time over the course of your study, please consider applying for the Radiology/CCTS Development Time Voucher Program (linked).","title":"Onboarding"},{"location":"scanner/onboarding/#onboarding-for-new-studies","text":"The first step in establishing a new study with CINL is to complete and submit our Inquiry and Quote Request forms. Both of these forms can be found either embedded or linked on the Research MRI Core site . MRI Only (Pre-Clinical/Basic Science) Inquiry Form: This is a short form for basic information. This form is embedded at the site linked above. \u201cMRI Only (Pre-Clinical/Basic Science) Review/Quote Request\u201d: This form will take more time to complete and submit. It includes a request for a PDF of the protocol, however an idea of the sequences and total scan length should suffice temporarily until a complete protocol is in place. Initially, a PI can review the form and submit it after the required fields are completed. Please email Eleanor at elewis1@uabmc.edu after you submit the forms. Feel free to reach out to us with questions. After Quote Request submission, a staff member will contact you about training, study logistics, billing, etc. Note A completed Quote Request Form is required to get a P-number, which is a how your study will be identified as well as confirm the current per hour scan rate. Please submit this form on RedCap and then notify CINL (cinl@uab.edu).","title":"Onboarding for New Studies"},{"location":"scanner/onboarding/#development-hours","text":"Each study receives up to 5 hours of development time for protocol setup and testing purposes. Follow our Calendar instructions (linked) for requesting this time keeping in mind to indicate the P-number along with PI name(s) and \u201cdevelopment\u201d when scheduling development time on the scan calendar. Once your study begins, CINL will not cover the cost of continued development time. If you believe you will need more than 5 hours of development time, or if you will require continued development time over the course of your study, please consider applying for the Radiology/CCTS Development Time Voucher Program (linked).","title":"Development Hours"},{"location":"scanner/scheduling/","text":"Scheduling and Billing \u00b6 Calendars \u00b6 Users that would like to view the MRI and interview room schedules or book time slots for their studies must have access to the CINL calendars. Two Google calendars are dedicated to our two Inverview Rooms and two calendars for the scheduling the Prisma, one for requesting scan time and the other for CINL personnel to confirm requests. To gain access to the following 4 google calendars, please send a request to Eleanor Yourich at elewis1@uabmc.edu. CINL Prisma Request CINL Prisma Confirmed CINL Highlands Interview Room 1 CINL Highlands Interview Room 2 You will need to provide Eleanor your email address. It is easiest to use a Gmail address (which will also integrate it into their already existing Google calendar). Warning This is a Google calendar, so no PHI should ever be entered. When requesting a scan on the CINL Prisma Request calendar, include the Study ID / P-number, along with PI name, for example: P18XXX \\<PI last name>. Please refer to the Prisma Calendar How-To Guide as it addresses each step in requesting time on the scanner. CINL Setup Time \u00b6 Note the 15 minute buffer time after clinical each weekday. This buffer is to provide a safeguard in case clinical needs additional time to wrap up. Keep in mind that this is a possible outcome when scheduling your scans over that buffer. Please reach out to Eleanor Yourich with any issues. User Setup Time \u00b6 There is up to a 30 minute window that we allow for setup and teardown (enough time to get the participant set up and then out of the scanner afterwards), and this 30-minute time can be scheduled separately from the actual scan time. If scan setup exceeds 30 minutes, then this extra time is billed for the study. Scan time is billed a minimum of 1 hour, and then in 15 minute intervals for time over 1 hour. Note We also ask Users to be mindful of the time requested on the scanner such that if the session is only 1.5 hours including setup time, that they do not request longer amounts of time. Example Calendar Event \u00b6 Requesting a Scanner Operator \u00b6 If you need someone to run the scan for your study, you can request a MRI technologist or Operationally (Level 2) certified individual trained to run your scan. On the calendar request, include \"Need Tech\". After the MR tech Elizabeth has learned how to perform your scan, she should be able to assist with research scans scheduled between 11:30AM - and completed by 8:00PM on weekdays. At least one MRI Safety trained member of your team will have to be present to instruct the MRI operator on your study's scanning protocol and if there are any particular nuances regarding how you like your scans to be acquired. We have weekend coverage from 9AM to 5PM most Saturdays and Sundays. Dr. Ryan Willoughby usually provides weekend coverage, but he must be familiar with your protocol before requesting him to scan. He is also not a registered MRI technologist so any studies that require a tech specifically will need to done during Elizabeth's hours. You must indicate on the Prisma Request Calendar if you need someone to scan for you and please refer to the Prisma Confirmed calendar when CINL staff is absent. If you wish, email Eleanor with your group's inquiry about availablity for your research scan at a particular date or time, but it is not required. which operator can be requested differs based on day and time of the scan. See the chart below for who can be requested for specific times. Scan Cancellations \u00b6 All cancellations must be reported in two ways: Use the CINL Request calendar to request a cancellation over the confirmed scan time you would like cancelled. Indicate your intent to cancel on the CINL Prisma Request calendar alongside the confirmed time (for example: \u201cCancel P18XXX (PI last name) scan\") Send a cancellation notice to the CINL Listserv. Email CINL-NOTICE@LISTSERV.UAB.EDU to indicate that the time slot on the scanner will be available. This list can also be used to let everyone know if an important piece of equipment goes down. Please do not use the list for anything else. Subscribing to CINL-NOTICE Listserv \u00b6 Click here , or alternatively, send an email to listserv@listserv.uab.edu with the email body as 'sub cinl-notice'. After which you\u2019ll receive an email to confirm your email address. After confirming your email address, you would start receiving cancellation emails from others on the list as well as be able to send your own notifications. No Show Policy \u00b6 If your research group does not show for the scan without cancelling via both the calendar and Listserv, then you will be billed for the amount of time booked on the calendar. This includes same day or day-before cancellations. Note Penalization ONLY occurs for no shows when the research group itself also does not show for the scan or appropriately indicate that the scan time is no longer needed (refer to 2 step cancellation process above). Billing \u00b6 For each study scan, we use the linked RedCap form for tracking and billing purposes. Fill this out at the scanner console where we have a tablet dedicated to this form. Note As of late 2021, the \"Save and Return Later\" function is failing to provide return codes. If this issue is resolved, we will let users know. The purpose of this function was so users could pre-fill some of the information, and then make note of the code to go back and continue to fill out the form at the scanner console. There are paper copies at the scanner console in case the online form is not working. Once at the scanner, please make sure to mark the time that your set-up starts and when the start and end of your scan is. You can also email yourself a copy of the form once it is completed.","title":"Scheduling and Billing"},{"location":"scanner/scheduling/#scheduling-and-billing","text":"","title":"Scheduling and Billing"},{"location":"scanner/scheduling/#calendars","text":"Users that would like to view the MRI and interview room schedules or book time slots for their studies must have access to the CINL calendars. Two Google calendars are dedicated to our two Inverview Rooms and two calendars for the scheduling the Prisma, one for requesting scan time and the other for CINL personnel to confirm requests. To gain access to the following 4 google calendars, please send a request to Eleanor Yourich at elewis1@uabmc.edu. CINL Prisma Request CINL Prisma Confirmed CINL Highlands Interview Room 1 CINL Highlands Interview Room 2 You will need to provide Eleanor your email address. It is easiest to use a Gmail address (which will also integrate it into their already existing Google calendar). Warning This is a Google calendar, so no PHI should ever be entered. When requesting a scan on the CINL Prisma Request calendar, include the Study ID / P-number, along with PI name, for example: P18XXX \\<PI last name>. Please refer to the Prisma Calendar How-To Guide as it addresses each step in requesting time on the scanner.","title":"Calendars"},{"location":"scanner/scheduling/#cinl-setup-time","text":"Note the 15 minute buffer time after clinical each weekday. This buffer is to provide a safeguard in case clinical needs additional time to wrap up. Keep in mind that this is a possible outcome when scheduling your scans over that buffer. Please reach out to Eleanor Yourich with any issues.","title":"CINL Setup Time"},{"location":"scanner/scheduling/#user-setup-time","text":"There is up to a 30 minute window that we allow for setup and teardown (enough time to get the participant set up and then out of the scanner afterwards), and this 30-minute time can be scheduled separately from the actual scan time. If scan setup exceeds 30 minutes, then this extra time is billed for the study. Scan time is billed a minimum of 1 hour, and then in 15 minute intervals for time over 1 hour. Note We also ask Users to be mindful of the time requested on the scanner such that if the session is only 1.5 hours including setup time, that they do not request longer amounts of time.","title":"User Setup Time"},{"location":"scanner/scheduling/#example-calendar-event","text":"","title":"Example Calendar Event"},{"location":"scanner/scheduling/#requesting-a-scanner-operator","text":"If you need someone to run the scan for your study, you can request a MRI technologist or Operationally (Level 2) certified individual trained to run your scan. On the calendar request, include \"Need Tech\". After the MR tech Elizabeth has learned how to perform your scan, she should be able to assist with research scans scheduled between 11:30AM - and completed by 8:00PM on weekdays. At least one MRI Safety trained member of your team will have to be present to instruct the MRI operator on your study's scanning protocol and if there are any particular nuances regarding how you like your scans to be acquired. We have weekend coverage from 9AM to 5PM most Saturdays and Sundays. Dr. Ryan Willoughby usually provides weekend coverage, but he must be familiar with your protocol before requesting him to scan. He is also not a registered MRI technologist so any studies that require a tech specifically will need to done during Elizabeth's hours. You must indicate on the Prisma Request Calendar if you need someone to scan for you and please refer to the Prisma Confirmed calendar when CINL staff is absent. If you wish, email Eleanor with your group's inquiry about availablity for your research scan at a particular date or time, but it is not required. which operator can be requested differs based on day and time of the scan. See the chart below for who can be requested for specific times.","title":"Requesting a Scanner Operator"},{"location":"scanner/scheduling/#scan-cancellations","text":"All cancellations must be reported in two ways: Use the CINL Request calendar to request a cancellation over the confirmed scan time you would like cancelled. Indicate your intent to cancel on the CINL Prisma Request calendar alongside the confirmed time (for example: \u201cCancel P18XXX (PI last name) scan\") Send a cancellation notice to the CINL Listserv. Email CINL-NOTICE@LISTSERV.UAB.EDU to indicate that the time slot on the scanner will be available. This list can also be used to let everyone know if an important piece of equipment goes down. Please do not use the list for anything else.","title":"Scan Cancellations"},{"location":"scanner/scheduling/#subscribing-to-cinl-notice-listserv","text":"Click here , or alternatively, send an email to listserv@listserv.uab.edu with the email body as 'sub cinl-notice'. After which you\u2019ll receive an email to confirm your email address. After confirming your email address, you would start receiving cancellation emails from others on the list as well as be able to send your own notifications.","title":"Subscribing to CINL-NOTICE Listserv"},{"location":"scanner/scheduling/#no-show-policy","text":"If your research group does not show for the scan without cancelling via both the calendar and Listserv, then you will be billed for the amount of time booked on the calendar. This includes same day or day-before cancellations. Note Penalization ONLY occurs for no shows when the research group itself also does not show for the scan or appropriately indicate that the scan time is no longer needed (refer to 2 step cancellation process above).","title":"No Show Policy"},{"location":"scanner/scheduling/#billing","text":"For each study scan, we use the linked RedCap form for tracking and billing purposes. Fill this out at the scanner console where we have a tablet dedicated to this form. Note As of late 2021, the \"Save and Return Later\" function is failing to provide return codes. If this issue is resolved, we will let users know. The purpose of this function was so users could pre-fill some of the information, and then make note of the code to go back and continue to fill out the form at the scanner console. There are paper copies at the scanner console in case the online form is not working. Once at the scanner, please make sure to mark the time that your set-up starts and when the start and end of your scan is. You can also email yourself a copy of the form once it is completed.","title":"Billing"},{"location":"scanner/training/","text":"Training and MRI Access \u00b6 Training \u00b6 In order to operate the scanner, two people who have been trained on MRI safety and at least one person who has been operationally trained must be present. Operationally trained individuals can include researchers who have undergone the relevant training or MRI technicians who can be requested to run the scanner during your session. To be present during an MRI scan, you must read over the following documents regarding MRI safety and then schedule a time to undergo training with Eleanor Yourich (elewis1@uabmc.edu) and Elizabeth Ingram (ekingram@uabmc.edu) through email. Safety Training Documents : MRI Safety Presentation Safety Training Policies and Procedures Safety Test After safety training is complete, a researcher can be operationally certified by scheduling operational training and testing through Eleanor and Elizabeth. MRI Key Card Access \u00b6 To obtain key card access to the Prisma MRI scanner area, message Ingia Gentry at CINL@uab.edu. Please provide the string of numbers at the bottom of the back side of the UAB ID badge (the string usually starts with a \"4*\" and ends with a \"-E\u201d).","title":"Training"},{"location":"scanner/training/#training-and-mri-access","text":"","title":"Training and MRI Access"},{"location":"scanner/training/#training","text":"In order to operate the scanner, two people who have been trained on MRI safety and at least one person who has been operationally trained must be present. Operationally trained individuals can include researchers who have undergone the relevant training or MRI technicians who can be requested to run the scanner during your session. To be present during an MRI scan, you must read over the following documents regarding MRI safety and then schedule a time to undergo training with Eleanor Yourich (elewis1@uabmc.edu) and Elizabeth Ingram (ekingram@uabmc.edu) through email. Safety Training Documents : MRI Safety Presentation Safety Training Policies and Procedures Safety Test After safety training is complete, a researcher can be operationally certified by scheduling operational training and testing through Eleanor and Elizabeth.","title":"Training"},{"location":"scanner/training/#mri-key-card-access","text":"To obtain key card access to the Prisma MRI scanner area, message Ingia Gentry at CINL@uab.edu. Please provide the string of numbers at the bottom of the back side of the UAB ID badge (the string usually starts with a \"4*\" and ends with a \"-E\u201d).","title":"MRI Key Card Access"},{"location":"scanner/xnat/","text":"XNAT \u00b6 About XNAT \u00b6 XNAT is an open-source imaging informatics platform developed at Washington University with a deployment here at UAB. It facilitates both MRI data storage in a common structure as well as sharing across labs both internal and external to UAB. It is free to use for all researchers at UAB. More information can be found at xnat.org . Why Use XNAT \u00b6 Can send data directly from the scanner to XNAT without copying to flash drive Easy to add collaborators to projects and share data across labs Can act as a data backup Common storage system makes data preprocessing pipelines more generalizeable This documenatation contains information on how to create and manage accounts, create projects, and upload and download data.","title":"XNAT"},{"location":"scanner/xnat/#xnat","text":"","title":"XNAT"},{"location":"scanner/xnat/#about-xnat","text":"XNAT is an open-source imaging informatics platform developed at Washington University with a deployment here at UAB. It facilitates both MRI data storage in a common structure as well as sharing across labs both internal and external to UAB. It is free to use for all researchers at UAB. More information can be found at xnat.org .","title":"About XNAT"},{"location":"scanner/xnat/#why-use-xnat","text":"Can send data directly from the scanner to XNAT without copying to flash drive Easy to add collaborators to projects and share data across labs Can act as a data backup Common storage system makes data preprocessing pipelines more generalizeable This documenatation contains information on how to create and manage accounts, create projects, and upload and download data.","title":"Why Use XNAT"},{"location":"scanner/xnat/account/","text":"User Registration and Accounts \u00b6 Permissions in XNAT for accessing and manipulating data are governed through each user's account. A user must have a valid and enabled account in order to log in and work with data in XNAT. Note An XNAT project can be set to allow guest access to allow users to view and download public data without an account. By default this setting is turned off, and must be enabled by an Administrator. Account Creation \u00b6 There are 3 ways in which a user account can be created: The user can register an account for themselves A new user can be invited to join XNAT by a current user who is a project owner A new user account can be created by an XNAT administrator Registering Your Own Account \u00b6 In a standard XNAT installation, user accounts must be created by either the user themselves or by the site administrator. Users will be given the option of registering for an account when they first visit the site. At UAB, navigate to xnat.rc.uab.edu/xnat and click Register on the home page. The following registration page will appear Fill out all of fields and submit registration. Your account should be ready to use. Being Invited to Join XNAT \u00b6 An existing project owner may wish to invite you to join XNAT with the purpose of granting you access to their project data. If they do so, you will receive an email from XNAT with a specially coded link called a Project Access Request. Clicking on that link will take you to a customized version of the account registration page, where you can either log in with an existing account, or create a new one. Contacting a Site Administrator \u00b6 If you have any trouble registering an account (or with anything else in this guide), message one of the site administrators or visit Rearch Computing office hours on Zoom. Office hours are from 10:00-12:00 on every Monday and Thursday. Zoom links can be found at rc.uab.edu. Admins: Matthew Defenderfer: mdefende@uab.edu","title":"User Registration and Accounts"},{"location":"scanner/xnat/account/#user-registration-and-accounts","text":"Permissions in XNAT for accessing and manipulating data are governed through each user's account. A user must have a valid and enabled account in order to log in and work with data in XNAT. Note An XNAT project can be set to allow guest access to allow users to view and download public data without an account. By default this setting is turned off, and must be enabled by an Administrator.","title":"User Registration and Accounts"},{"location":"scanner/xnat/account/#account-creation","text":"There are 3 ways in which a user account can be created: The user can register an account for themselves A new user can be invited to join XNAT by a current user who is a project owner A new user account can be created by an XNAT administrator","title":"Account Creation"},{"location":"scanner/xnat/account/#registering-your-own-account","text":"In a standard XNAT installation, user accounts must be created by either the user themselves or by the site administrator. Users will be given the option of registering for an account when they first visit the site. At UAB, navigate to xnat.rc.uab.edu/xnat and click Register on the home page. The following registration page will appear Fill out all of fields and submit registration. Your account should be ready to use.","title":"Registering Your Own Account"},{"location":"scanner/xnat/account/#being-invited-to-join-xnat","text":"An existing project owner may wish to invite you to join XNAT with the purpose of granting you access to their project data. If they do so, you will receive an email from XNAT with a specially coded link called a Project Access Request. Clicking on that link will take you to a customized version of the account registration page, where you can either log in with an existing account, or create a new one.","title":"Being Invited to Join XNAT"},{"location":"scanner/xnat/account/#contacting-a-site-administrator","text":"If you have any trouble registering an account (or with anything else in this guide), message one of the site administrators or visit Rearch Computing office hours on Zoom. Office hours are from 10:00-12:00 on every Monday and Thursday. Zoom links can be found at rc.uab.edu. Admins: Matthew Defenderfer: mdefende@uab.edu","title":"Contacting a Site Administrator"},{"location":"scanner/xnat/file_management/","text":"File Management \u00b6 Uploading Files \u00b6 Uploading from the scanner \u00b6 One of the best ways to get your files to XNAT is to send them directly from the scanner immediately after the scan session ends. Anything sent using this method will go to XNAT, but if you want your files to be associated with your porject, and want to access your files without the help of an administrator, you should make sure you know your project's Project ID. If you are collection data for a new project, it only takes a few minutes to create a new project in XNAT In order to associate the scans with your project, you need to add a tag with your Project ID during the scan setup process. Once you make it to the Patient Confirmation page, locate the Study Comment entry under Requested Procedure . Input \"Project: your project ID \" with no quotes. For example, if a Project ID was BRF, you would insert \"Project: BRF\" with no quotes. Once you have completed data collection, locate your data in the Patient Browser. Select the folder with your patient's name. Do not select any of the scans, only select the folder with the patient name. In the Patient Browser window, select Transfer >> Send To and select XNAT. Select Send to queue your files to be sent to XNAT. This process can be slow, but will operate in the background of the computer, allowing subsequent investigators to begin scanning. Send to OSIRIX in the same way to have a backup. Note Only files in DICOM format can be sent to XNAT from the Prisma scanner. Magnetic resonance spectroscopy images cannot be sent to or stored on XNAT. These scans will have to be downloaded directly from the scanner. DicomBrowser \u00b6 DicomBrowser can be used to view images stored on your computer or flash drive and can upload them to XNAT. It is available on Mac, Windows, and Linux from https://wiki.xnat.org/xnat-tools/dicombrowser . You can open individual images or folders of images by clicking File >> Open and navigating to the location of the files on your computer. Once DicomBrowser loads your files, you can select one or more files or folders and click View >> View selected images to open up a toolbar that allows you to view, animate, and process your files. If you save after processing your files, DicomBrowser will overwrite the original image files, so it is always important to have a backup copy of your data. Uploading files using DicomBrowser is easy but not very intuitive. Once your files are open in DicomBrowser, click on the folder in the left sidebar containing all of the files you want to upload to your project. You will see a long list of tags which represent additional information stored in each image on your computer. Find the tag marked Study Description and change the text in the column labeled \"Value\" to the Project ID of your project. With your files still highlighted, click File >> Send to open up dialogue box. Change the default values to the values below: Remote host: xnat.rc.uab.edu Port: 8104 Remote AE Title: XNAT Local AE Title: DicomBrowser Downloading Files \u00b6 Using XNAT's Downloader \u00b6 XNAT's downloader requires Java to run, so make sure you have the latest version of Java installed on a Java-compatible browser like Internet Explorer or Safari In order to begin your download, click your project file and select Download Images from the actions bar on the right side of the screen. The next page allows you to select imaging sessions and scan types you would like to download. Click Submit. You will be taken to a new page, and will have to wait several seconds for a Java window to appear, which allows you to select a destination folder on your computer and then click Start to download. If the Browse and Start buttons do not appear on this page, Java is not functioning on your browser (See Installing Java on the previous page of this guide).","title":"File Management"},{"location":"scanner/xnat/file_management/#file-management","text":"","title":"File Management"},{"location":"scanner/xnat/file_management/#uploading-files","text":"","title":"Uploading Files"},{"location":"scanner/xnat/file_management/#uploading-from-the-scanner","text":"One of the best ways to get your files to XNAT is to send them directly from the scanner immediately after the scan session ends. Anything sent using this method will go to XNAT, but if you want your files to be associated with your porject, and want to access your files without the help of an administrator, you should make sure you know your project's Project ID. If you are collection data for a new project, it only takes a few minutes to create a new project in XNAT In order to associate the scans with your project, you need to add a tag with your Project ID during the scan setup process. Once you make it to the Patient Confirmation page, locate the Study Comment entry under Requested Procedure . Input \"Project: your project ID \" with no quotes. For example, if a Project ID was BRF, you would insert \"Project: BRF\" with no quotes. Once you have completed data collection, locate your data in the Patient Browser. Select the folder with your patient's name. Do not select any of the scans, only select the folder with the patient name. In the Patient Browser window, select Transfer >> Send To and select XNAT. Select Send to queue your files to be sent to XNAT. This process can be slow, but will operate in the background of the computer, allowing subsequent investigators to begin scanning. Send to OSIRIX in the same way to have a backup. Note Only files in DICOM format can be sent to XNAT from the Prisma scanner. Magnetic resonance spectroscopy images cannot be sent to or stored on XNAT. These scans will have to be downloaded directly from the scanner.","title":"Uploading from the scanner"},{"location":"scanner/xnat/file_management/#dicombrowser","text":"DicomBrowser can be used to view images stored on your computer or flash drive and can upload them to XNAT. It is available on Mac, Windows, and Linux from https://wiki.xnat.org/xnat-tools/dicombrowser . You can open individual images or folders of images by clicking File >> Open and navigating to the location of the files on your computer. Once DicomBrowser loads your files, you can select one or more files or folders and click View >> View selected images to open up a toolbar that allows you to view, animate, and process your files. If you save after processing your files, DicomBrowser will overwrite the original image files, so it is always important to have a backup copy of your data. Uploading files using DicomBrowser is easy but not very intuitive. Once your files are open in DicomBrowser, click on the folder in the left sidebar containing all of the files you want to upload to your project. You will see a long list of tags which represent additional information stored in each image on your computer. Find the tag marked Study Description and change the text in the column labeled \"Value\" to the Project ID of your project. With your files still highlighted, click File >> Send to open up dialogue box. Change the default values to the values below: Remote host: xnat.rc.uab.edu Port: 8104 Remote AE Title: XNAT Local AE Title: DicomBrowser","title":"DicomBrowser"},{"location":"scanner/xnat/file_management/#downloading-files","text":"","title":"Downloading Files"},{"location":"scanner/xnat/file_management/#using-xnats-downloader","text":"XNAT's downloader requires Java to run, so make sure you have the latest version of Java installed on a Java-compatible browser like Internet Explorer or Safari In order to begin your download, click your project file and select Download Images from the actions bar on the right side of the screen. The next page allows you to select imaging sessions and scan types you would like to download. Click Submit. You will be taken to a new page, and will have to wait several seconds for a Java window to appear, which allows you to select a destination folder on your computer and then click Start to download. If the Browse and Start buttons do not appear on this page, Java is not functioning on your browser (See Installing Java on the previous page of this guide).","title":"Using XNAT's Downloader"},{"location":"scanner/xnat/projects/","text":"XNAT Projects \u00b6 There are several different methods that you can use to upload files to XNAT. In order to make sure your files are properly organized and accessible to you and others working on your project, it is important to first create an XNAT project before uploading anything. Note All files uploaded to XNAT that you do not assign to a specific project will end up in the prearchive. The prearchive is accessible only to administrators, and so you will need an administrator's assistance to gain access to your files and to move them to the correct project. Creating a New Project \u00b6 On the Home Page, click New >> Project from the dropdown menu to create a new project. After selecting the Project Title and an abbreviated version of your title for your Running Title, you will need to set a Project ID. Once set, this Project ID can never be changed, and will be used by XNAT and other programs to send files to your project and to reference your project for various other purposes. You can also write a description for your project, assign searchable tags to it, or assign your project to a PI. None of these things are necessary, and all can be added or changed at a later time. User Roles and Permissions \u00b6 XNAT defines 3 common project roles: Owners, Members, and Collaborators. Project owners are able to add new users to a project and assign roles. Each different role has different permissions for data access: Role/Activity Owners Members Collaborators Create Data C C Read/Download Data R R R Update Data U U Delete Data D User Permission Structure Project Owners can read, insert, modify, and delete anything (and everything) associated with your project. They can also add additional users to your project and modify the data types associated with your project. Project Members can manage the data in your project. They can read, insert, and modify subjects and experiments in your project. They cannot modify the project users and data types. Project Collaborators have read-only access on all of the data in your project. They cannot insert or modify data owned by your project. They can download your data and use it within their projects. Managing User Access \u00b6 Users can be added to your project and assigned roles using the Manage User Access Dialogue","title":"XNAT Projects"},{"location":"scanner/xnat/projects/#xnat-projects","text":"There are several different methods that you can use to upload files to XNAT. In order to make sure your files are properly organized and accessible to you and others working on your project, it is important to first create an XNAT project before uploading anything. Note All files uploaded to XNAT that you do not assign to a specific project will end up in the prearchive. The prearchive is accessible only to administrators, and so you will need an administrator's assistance to gain access to your files and to move them to the correct project.","title":"XNAT Projects"},{"location":"scanner/xnat/projects/#creating-a-new-project","text":"On the Home Page, click New >> Project from the dropdown menu to create a new project. After selecting the Project Title and an abbreviated version of your title for your Running Title, you will need to set a Project ID. Once set, this Project ID can never be changed, and will be used by XNAT and other programs to send files to your project and to reference your project for various other purposes. You can also write a description for your project, assign searchable tags to it, or assign your project to a PI. None of these things are necessary, and all can be added or changed at a later time.","title":"Creating a New Project"},{"location":"scanner/xnat/projects/#user-roles-and-permissions","text":"XNAT defines 3 common project roles: Owners, Members, and Collaborators. Project owners are able to add new users to a project and assign roles. Each different role has different permissions for data access: Role/Activity Owners Members Collaborators Create Data C C Read/Download Data R R R Update Data U U Delete Data D User Permission Structure Project Owners can read, insert, modify, and delete anything (and everything) associated with your project. They can also add additional users to your project and modify the data types associated with your project. Project Members can manage the data in your project. They can read, insert, and modify subjects and experiments in your project. They cannot modify the project users and data types. Project Collaborators have read-only access on all of the data in your project. They cannot insert or modify data owned by your project. They can download your data and use it within their projects.","title":"User Roles and Permissions"},{"location":"scanner/xnat/projects/#managing-user-access","text":"Users can be added to your project and assigned roles using the Manage User Access Dialogue","title":"Managing User Access"}]}